{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["gRYPHQyJ2n81","1yu4r2KZ3CrW","GHWyqfm-3JiG","iauZD-uv3f_U"],"authorship_tag":"ABX9TyN0j0RDsDtXNFroabzysp1a"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Setting up the notebook"],"metadata":{"id":"gRYPHQyJ2n81"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"n9d_v-M-2ZIt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730889143520,"user_tz":-120,"elapsed":60961,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"}},"outputId":"550610f5-e334-4881-d9fd-d32e0590ae25"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pip==24.0 in /usr/local/lib/python3.10/dist-packages (24.0)\n","Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.10/dist-packages (1.23.5)\n","Collecting tensorboardX\n","  Using cached tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.23.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (24.1)\n","Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n","Using cached tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n","Installing collected packages: tensorboardX\n","Successfully installed tensorboardX-2.6.2.2\n","Requirement already satisfied: subword-nmt in /usr/local/lib/python3.10/dist-packages (0.3.8)\n","Requirement already satisfied: mock in /usr/local/lib/python3.10/dist-packages (from subword-nmt) (5.1.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from subword-nmt) (4.66.6)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\n"]}],"source":["# installing packages\n","!pip install pip==24.0\n","!pip install numpy==1.23.5\n","!pip install tensorboardX\n","!pip install subword-nmt\n","!pip install sentencepiece"]},{"cell_type":"code","source":["# importing packages\n","import numpy\n","import os\n","import tensorboardX\n","import sentencepiece as spm"],"metadata":{"id":"-A7kebwS2yxi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# mounting google drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"id":"3Xe4X1q7226i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730889173092,"user_tz":-120,"elapsed":21687,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"}},"outputId":"d0157907-38ff-49b3-cbc7-669e5cf85987"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["source_code = 'eng'\n","target_code = 'tso'"],"metadata":{"id":"UzLT4biR24Hh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# change working directory\n","os.chdir(f'/content/drive/MyDrive/Research/eng-to-{target_code}')\n","\n","# installing fairseq\n","#!git clone https://github.com/pytorch/fairseq.git\n","%cd fairseq\n","!pip install --editable ./"],"metadata":{"id":"SX20tTVi26QU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730889694005,"user_tz":-120,"elapsed":520915,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"}},"outputId":"b044d9b8-26b4-4b51-b9dd-680bd89deace"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Research/eng-to-tso/fairseq\n","Obtaining file:///content/drive/MyDrive/Research/eng-to-tso/fairseq\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n","  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (1.17.1)\n","Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (3.0.11)\n","Collecting hydra-core<1.1,>=1.0.7 (from fairseq==0.12.2)\n","  Downloading hydra_core-1.0.7-py3-none-any.whl.metadata (3.7 kB)\n","Collecting omegaconf<2.1 (from fairseq==0.12.2)\n","  Downloading omegaconf-2.0.6-py3-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: numpy>=1.21.3 in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (1.23.5)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (2024.9.11)\n","Collecting sacrebleu>=1.4.12 (from fairseq==0.12.2)\n","  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (2.5.0+cu121)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (4.66.6)\n","Collecting bitarray (from fairseq==0.12.2)\n","  Downloading bitarray-3.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (32 kB)\n","Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (2.5.0+cu121)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (1.5.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (24.1)\n","Collecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq==0.12.2)\n","  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq==0.12.2) (6.0.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq==0.12.2) (4.12.2)\n","Collecting portalocker (from sacrebleu>=1.4.12->fairseq==0.12.2)\n","  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.2) (0.9.0)\n","Collecting colorama (from sacrebleu>=1.4.12->fairseq==0.12.2)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.2) (5.3.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (3.16.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13->fairseq==0.12.2) (1.3.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq==0.12.2) (2.22)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fairseq==0.12.2) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fairseq==0.12.2) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fairseq==0.12.2) (3.5.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->fairseq==0.12.2) (3.0.2)\n","Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n","Downloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bitarray-3.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (278 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.3/278.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n","Building wheels for collected packages: fairseq, antlr4-python3-runtime\n","  Building editable for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fairseq: filename=fairseq-0.12.2-0.editable-cp310-cp310-linux_x86_64.whl size=9581 sha256=98482531860113099fde0fbf0da1f1ae6574f6afff29e0788afb9e2b22438cd2\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-g5i7zoso/wheels/9e/98/8e/ef4c5761efd94805bbd4d6c28ef61a86b874a20d6696dba7ca\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141214 sha256=d030030ce9a80e849777b65b6da4d490020eaf424a21ee3080b62adb97f5a4d0\n","  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n","Successfully built fairseq antlr4-python3-runtime\n","\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0mInstalling collected packages: bitarray, antlr4-python3-runtime, portalocker, omegaconf, colorama, sacrebleu, hydra-core, fairseq\n","Successfully installed antlr4-python3-runtime-4.8 bitarray-3.0.0 colorama-0.4.6 fairseq-0.12.2 hydra-core-1.0.7 omegaconf-2.0.6 portalocker-2.10.1 sacrebleu-2.4.3\n"]}]},{"cell_type":"markdown","source":["## Evaluate Model on Raw Test and Global Test Sets"],"metadata":{"id":"FuS41Dcr3Zr9"}},{"cell_type":"code","source":["import sacrebleu"],"metadata":{"id":"3ErTAQvT1ZX8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["before_punc = '!,.:;?)'\n","def remove_whitespace_before(segment, punc):\n","  \"\"\"\n","  This function looks for punctuation in a segment and removes the whitespace\n","  before the punctuation mark.\n","\n","  Args:\n","    segment (str): segment to be processed.\n","    punc (str): string of punctuation marks.\n","\n","  Returns:\n","    The segment with whitespace removed before punctuation marks in punc.\n","  \"\"\"\n","  punc_positions = []\n","  for i, symbol in enumerate(segment):\n","    if symbol in punc:\n","      punc_positions.append(i)\n","\n","  punc_positions.reverse()\n","  for pos in punc_positions:\n","    if segment[pos-1] == \" \":\n","      segment = segment[0:pos-1] + segment[pos:]\n","\n","  return segment"],"metadata":{"id":"ziWmWD5z1Zz4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### BPE"],"metadata":{"id":"_DwfMJ5G3ea-"}},{"cell_type":"code","source":["# change working directory\n","os.chdir(f'/content/drive/MyDrive/Research/eng-to-{target_code}/bpe')"],"metadata":{"id":"JgLGxEbADw75"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mkdir -p trained_model\n","!cp data-bin/dict.eng.txt trained_model/dict.eng.txt\n","!cp data-bin/dict.tso.txt trained_model/dict.tso.txt\n","!cp data/bpe.codes.4000 trained_model/bpe.codes.4000\n","!cp checkpoints-bpe/checkpoint_best.pt trained_model/model.pt"],"metadata":{"id":"FIgSPIZOFR6a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!fairseq-interactive \\\n","--path trained_model/model.pt \\\n","--source-lang eng \\\n","--target-lang tso \\\n","--bpe 'subword_nmt' \\\n","--bpe-codes trained_model/bpe.codes.4000 \\\n","--beam 5 \\\n","--lenpen 1 \\\n","--seed 2024 \\\n","--max-len-a 0 \\\n","--max-len-b 100 \\\n","--quiet \\\n","--remove-bpe \\\n","--buffer-size 100 \\\n","--input /content/drive/MyDrive/Research/eng-to-tso/cleaned-data/clean_gtest.eng \\\n","trained_model/ | grep -P \"D-[0-9]+\" | cut -f3 > trained_model/translations_gtest"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yoYP9oQhD2vr","executionInfo":{"status":"ok","timestamp":1730890791351,"user_tz":-120,"elapsed":202597,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"}},"outputId":"7ee042bb-f120-4ad0-dbe4-869c27a724c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-11-06 10:56:33.035930: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-06 10:56:33.061054: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-06 10:56:33.068532: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-06 10:56:33.086453: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-06 10:56:34.528550: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-11-06 10:56:45 | INFO | fairseq_cli.interactive | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 2024, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'trained_model/model.pt', 'post_process': 'subword_nmt', 'quiet': True, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 100, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 100, 'input': '/content/drive/MyDrive/Research/eng-to-tso/cleaned-data/clean_gtest.eng'}, 'model': None, 'task': {'_name': 'translation', 'data': 'trained_model/', 'source_lang': 'eng', 'target_lang': 'tso', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': {'_name': 'subword_nmt', 'bpe_codes': 'trained_model/bpe.codes.4000', 'bpe_separator': '@@'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2024-11-06 10:56:45 | INFO | fairseq.tasks.translation | [eng] dictionary: 4160 types\n","2024-11-06 10:56:45 | INFO | fairseq.tasks.translation | [tso] dictionary: 4160 types\n","2024-11-06 10:56:45 | INFO | fairseq_cli.interactive | loading model(s) from trained_model/model.pt\n","/content/drive/MyDrive/Research/eng-to-tso/fairseq/fairseq/checkpoint_utils.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state = torch.load(f, map_location=torch.device(\"cpu\"))\n","2024-11-06 10:56:46 | INFO | fairseq_cli.interactive | Sentence buffer size: 100\n","2024-11-06 10:56:46 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n","2024-11-06 10:56:46 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n","2024-11-06 10:56:46 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:56:46 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:56:46 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:56:46 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:57:11 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:57:11 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:57:11 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:57:11 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:57:51 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:57:51 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:57:51 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:57:51 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:58:27 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:58:27 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:58:27 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:58:27 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:59:12 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:59:12 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:59:12 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:59:12 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:59:48 | INFO | fairseq_cli.interactive | Total time: 183.263 seconds; translation time: 179.827\n"]}]},{"cell_type":"code","source":["!fairseq-interactive \\\n","--path trained_model/model.pt \\\n","--source-lang eng \\\n","--target-lang tso \\\n","--bpe 'subword_nmt' \\\n","--bpe-codes trained_model/bpe.codes.4000 \\\n","--beam 5 \\\n","--lenpen 1 \\\n","--seed 2024 \\\n","--max-len-a 0 \\\n","--max-len-b 100 \\\n","--quiet \\\n","--remove-bpe \\\n","--buffer-size 100 \\\n","--input /content/drive/MyDrive/Research/eng-to-tso/cleaned-data/test.eng \\\n","trained_model/ | grep -P \"D-[0-9]+\" | cut -f3 > trained_model/translations_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H8Vc7sHCCEV3","executionInfo":{"status":"ok","timestamp":1730891300951,"user_tz":-120,"elapsed":509603,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"}},"outputId":"03e01cef-25e9-48b4-a24e-b7e5241f6bba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-11-06 10:59:55.160062: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-06 10:59:55.199115: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-06 10:59:55.210870: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-06 10:59:55.237224: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-06 10:59:56.929944: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-11-06 11:00:08 | INFO | fairseq_cli.interactive | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 2024, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'trained_model/model.pt', 'post_process': 'subword_nmt', 'quiet': True, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 100, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 100, 'input': '/content/drive/MyDrive/Research/eng-to-tso/cleaned-data/test.eng'}, 'model': None, 'task': {'_name': 'translation', 'data': 'trained_model/', 'source_lang': 'eng', 'target_lang': 'tso', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': {'_name': 'subword_nmt', 'bpe_codes': 'trained_model/bpe.codes.4000', 'bpe_separator': '@@'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2024-11-06 11:00:08 | INFO | fairseq.tasks.translation | [eng] dictionary: 4160 types\n","2024-11-06 11:00:08 | INFO | fairseq.tasks.translation | [tso] dictionary: 4160 types\n","2024-11-06 11:00:08 | INFO | fairseq_cli.interactive | loading model(s) from trained_model/model.pt\n","/content/drive/MyDrive/Research/eng-to-tso/fairseq/fairseq/checkpoint_utils.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state = torch.load(f, map_location=torch.device(\"cpu\"))\n","2024-11-06 11:00:09 | INFO | fairseq_cli.interactive | Sentence buffer size: 100\n","2024-11-06 11:00:09 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n","2024-11-06 11:00:09 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n","2024-11-06 11:00:10 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:00:10 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:00:10 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:00:10 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:00:26 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:00:26 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:00:26 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:00:26 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:00:43 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:00:43 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:00:43 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:00:43 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:00:59 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:00:59 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:00:59 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:00:59 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:01:17 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:01:17 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:01:17 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:01:17 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:01:36 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:01:36 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:01:36 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:01:36 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:01:51 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:01:51 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:01:51 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:01:51 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:02:09 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:02:09 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:02:09 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:02:09 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:02:23 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:02:23 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:02:23 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:02:23 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:02:38 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:02:38 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:02:38 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:02:38 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:02:54 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:02:54 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:02:54 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:02:54 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:03:08 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:03:08 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:03:08 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:03:08 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:03:24 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:03:24 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:03:24 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:03:24 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:03:41 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:03:41 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:03:41 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:03:41 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:03:59 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:03:59 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:03:59 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:03:59 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:04:16 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:04:16 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:04:16 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:04:16 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:04:32 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:04:32 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:04:32 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:04:32 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:04:50 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:04:50 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:04:50 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:04:50 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:05:05 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:05:05 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:05:05 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:05:05 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:05:21 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:05:21 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:05:21 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:05:21 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:05:36 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:05:36 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:05:36 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:05:36 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:05:51 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:05:51 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:05:51 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:05:51 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:06:06 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:06:06 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:06:06 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:06:06 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:06:23 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:06:23 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:06:23 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:06:23 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:06:40 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:06:40 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:06:40 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:06:40 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:06:57 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:06:57 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:06:57 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:06:57 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:07:12 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:07:12 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:07:12 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:07:12 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:07:27 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:07:27 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:07:27 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:07:27 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:07:44 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:07:44 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:07:44 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:07:44 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:08:01 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:08:01 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:08:01 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:08:01 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:08:16 | INFO | fairseq_cli.interactive | Total time: 488.105 seconds; translation time: 478.001\n"]}]},{"cell_type":"code","source":["# change working directory\n","os.chdir(f'/content/drive/MyDrive/Research/eng-to-{target_code}/cleaned-data')"],"metadata":{"id":"aohCLVVYEJzP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/bpe/trained_model/translations_gtest'"],"metadata":{"id":"2fZqNykwEUSB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# post-processing predictions\n","with open(translations_path, 'r', encoding='utf-8') as f:\n","  segments = f.read().splitlines()\n","\n","for i in range(len(segments)):\n","  segments[i] = remove_whitespace_before(segments[i], before_punc)\n","\n","post_translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/bpe/trained_model/post_process_translations_gtest'\n","with open(post_translations_path, 'w') as f:\n","  for segment in segments:\n","    f.write(segment + '\\n')"],"metadata":{"id":"jlPugTCJEZqn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/bpe/trained_model/translations_test'"],"metadata":{"id":"t88XqQljCQIv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# post-processing predictions\n","with open(translations_path, 'r', encoding='utf-8') as f:\n","  segments = f.read().splitlines()\n","\n","for i in range(len(segments)):\n","  segments[i] = remove_whitespace_before(segments[i], before_punc)\n","\n","post_translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/bpe/trained_model/post_process_translations_test'\n","with open(post_translations_path, 'w') as f:\n","  for segment in segments:\n","    f.write(segment + '\\n')"],"metadata":{"id":"1ADDYStkCS3Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ULM"],"metadata":{"id":"iauZD-uv3f_U"}},{"cell_type":"code","source":["# change working directory\n","os.chdir(f'/content/drive/MyDrive/Research/eng-to-{target_code}/ulm')"],"metadata":{"id":"enHL8Yr7E-YQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mkdir -p trained_model\n","!cp data-bin/dict.eng.txt trained_model/dict.eng.txt\n","!cp data-bin/dict.tso.txt trained_model/dict.tso.txt\n","!cp data/joint.model trained_model/joint.model\n","!cp checkpoints-ulm/checkpoint_best.pt trained_model/model.pt"],"metadata":{"id":"Ve2z0uigXtBX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!fairseq-interactive \\\n","--path trained_model/model.pt \\\n","--source-lang eng \\\n","--target-lang tso \\\n","--bpe 'sentencepiece' \\\n","--sentencepiece-model trained_model/joint.model \\\n","--beam 5 \\\n","--lenpen 1 \\\n","--seed 2024 \\\n","--max-len-a 0 \\\n","--max-len-b 100 \\\n","--quiet \\\n","--remove-bpe sentencepiece \\\n","--buffer-size 100 \\\n","--input /content/drive/MyDrive/Research/eng-to-tso/cleaned-data/clean_gtest.eng \\\n","trained_model/ | grep -P \"H-[0-9]+\" | cut -f3 > trained_model/translations_gtest"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yXQ1DtgRFFWk","executionInfo":{"status":"ok","timestamp":1730891915331,"user_tz":-120,"elapsed":219533,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"}},"outputId":"84d341cb-463b-4121-f447-f5cf502afbdd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-11-06 11:14:59.548822: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-06 11:14:59.585674: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-06 11:14:59.596221: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-06 11:14:59.622453: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-06 11:15:01.300566: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-11-06 11:15:13 | INFO | fairseq_cli.interactive | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 2024, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'trained_model/model.pt', 'post_process': 'sentencepiece', 'quiet': True, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 100, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 100, 'input': '/content/drive/MyDrive/Research/eng-to-tso/cleaned-data/clean_gtest.eng'}, 'model': None, 'task': {'_name': 'translation', 'data': 'trained_model/', 'source_lang': 'eng', 'target_lang': 'tso', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': {'_name': 'sentencepiece', 'sentencepiece_model': 'trained_model/joint.model', 'sentencepiece_enable_sampling': False, 'sentencepiece_alpha': None}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2024-11-06 11:15:13 | INFO | fairseq.tasks.translation | [eng] dictionary: 3992 types\n","2024-11-06 11:15:13 | INFO | fairseq.tasks.translation | [tso] dictionary: 3992 types\n","2024-11-06 11:15:13 | INFO | fairseq_cli.interactive | loading model(s) from trained_model/model.pt\n","/content/drive/MyDrive/Research/eng-to-tso/fairseq/fairseq/checkpoint_utils.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state = torch.load(f, map_location=torch.device(\"cpu\"))\n","2024-11-06 11:15:14 | INFO | fairseq_cli.interactive | Sentence buffer size: 100\n","2024-11-06 11:15:14 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n","2024-11-06 11:15:14 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n","2024-11-06 11:15:14 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:15:14 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:15:14 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:15:14 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:15:42 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:15:42 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:15:42 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:15:42 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:16:28 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:16:28 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:16:28 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:16:28 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:17:09 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:17:09 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:17:09 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:17:09 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:17:52 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:17:52 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:17:52 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:17:52 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:18:32 | INFO | fairseq_cli.interactive | Total time: 198.545 seconds; translation time: 195.482\n"]}]},{"cell_type":"code","source":["!fairseq-interactive \\\n","--path trained_model/model.pt \\\n","--source-lang eng \\\n","--target-lang tso \\\n","--bpe 'sentencepiece' \\\n","--sentencepiece-model trained_model/joint.model \\\n","--beam 5 \\\n","--lenpen 1 \\\n","--seed 2024 \\\n","--max-len-a 0 \\\n","--max-len-b 100 \\\n","--quiet \\\n","--remove-bpe sentencepiece \\\n","--buffer-size 100 \\\n","--input /content/drive/MyDrive/Research/eng-to-tso/cleaned-data/test.eng \\\n","trained_model/ | grep -P \"H-[0-9]+\" | cut -f3 > trained_model/translations_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WYeDcfMYCnD8","executionInfo":{"status":"ok","timestamp":1730892419891,"user_tz":-120,"elapsed":504564,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"}},"outputId":"67b7e22c-982e-434e-b5c3-a9ec65f26d68"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-11-06 11:18:37.822432: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-06 11:18:37.848920: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-06 11:18:37.856837: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-06 11:18:37.876961: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-06 11:18:39.307520: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-11-06 11:18:50 | INFO | fairseq_cli.interactive | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 2024, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'trained_model/model.pt', 'post_process': 'sentencepiece', 'quiet': True, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 100, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 100, 'input': '/content/drive/MyDrive/Research/eng-to-tso/cleaned-data/test.eng'}, 'model': None, 'task': {'_name': 'translation', 'data': 'trained_model/', 'source_lang': 'eng', 'target_lang': 'tso', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': {'_name': 'sentencepiece', 'sentencepiece_model': 'trained_model/joint.model', 'sentencepiece_enable_sampling': False, 'sentencepiece_alpha': None}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2024-11-06 11:18:50 | INFO | fairseq.tasks.translation | [eng] dictionary: 3992 types\n","2024-11-06 11:18:50 | INFO | fairseq.tasks.translation | [tso] dictionary: 3992 types\n","2024-11-06 11:18:50 | INFO | fairseq_cli.interactive | loading model(s) from trained_model/model.pt\n","/content/drive/MyDrive/Research/eng-to-tso/fairseq/fairseq/checkpoint_utils.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state = torch.load(f, map_location=torch.device(\"cpu\"))\n","2024-11-06 11:18:50 | INFO | fairseq_cli.interactive | Sentence buffer size: 100\n","2024-11-06 11:18:50 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n","2024-11-06 11:18:50 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n","2024-11-06 11:18:50 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:18:50 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:18:50 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:18:50 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:19:06 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:19:06 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:19:06 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:19:06 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:19:23 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:19:23 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:19:23 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:19:23 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:19:39 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:19:39 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:19:39 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:19:39 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:19:58 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:19:58 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:19:58 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:19:58 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:20:14 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:20:14 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:20:14 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:20:14 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:20:30 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:20:30 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:20:30 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:20:30 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:20:47 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:20:47 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:20:47 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:20:47 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:21:02 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:21:02 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:21:02 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:21:02 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:21:16 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:21:16 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:21:16 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:21:16 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:21:34 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:21:34 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:21:34 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:21:34 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:21:48 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:21:48 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:21:48 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:21:48 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:22:04 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:22:04 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:22:04 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:22:04 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:22:20 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:22:20 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:22:20 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:22:20 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:22:38 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:22:38 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:22:38 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:22:38 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:22:54 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:22:54 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:22:54 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:22:54 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:23:11 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:23:11 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:23:11 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:23:11 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:23:29 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:23:29 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:23:29 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:23:29 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:23:43 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:23:43 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:23:43 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:23:43 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:24:00 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:24:00 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:24:00 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:24:00 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:24:14 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:24:14 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:24:14 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:24:14 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:24:31 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:24:31 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:24:31 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:24:31 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:24:46 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:24:46 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:24:46 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:24:46 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:25:01 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:25:01 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:25:01 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:25:01 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:25:17 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:25:17 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:25:17 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:25:17 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:25:34 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:25:34 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:25:34 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:25:34 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:25:49 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:25:49 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:25:49 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:25:49 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:26:04 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:26:04 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:26:04 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:26:04 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:26:23 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:26:23 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:26:23 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:26:23 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:26:40 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:26:40 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:26:40 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:26:40 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:26:56 | INFO | fairseq_cli.interactive | Total time: 486.610 seconds; translation time: 477.520\n"]}]},{"cell_type":"code","source":["# change working directory\n","os.chdir(f'/content/drive/MyDrive/Research/eng-to-{target_code}/cleaned-data')"],"metadata":{"id":"OoR_vcnXLFwc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/ulm/trained_model/translations_gtest'"],"metadata":{"id":"vjwlmMzS1xzV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# post-processing predictions\n","with open(translations_path, 'r', encoding='utf-8') as f:\n","  segments = f.read().splitlines()\n","\n","for i in range(len(segments)):\n","  segments[i] = remove_whitespace_before(segments[i], before_punc)\n","\n","post_translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/ulm/trained_model/post_process_translations_gtest'\n","with open(post_translations_path, 'w') as f:\n","  for segment in segments:\n","    f.write(segment + '\\n')"],"metadata":{"id":"xG6s-pyY1zeb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/ulm/trained_model/translations_test'"],"metadata":{"id":"UyVcVRu9CvfF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# post-processing predictions\n","with open(translations_path, 'r', encoding='utf-8') as f:\n","  segments = f.read().splitlines()\n","\n","for i in range(len(segments)):\n","  segments[i] = remove_whitespace_before(segments[i], before_punc)\n","\n","post_translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/ulm/trained_model/post_process_translations_test'\n","with open(post_translations_path, 'w') as f:\n","  for segment in segments:\n","    f.write(segment + '\\n')"],"metadata":{"id":"kYRd47dGCzDT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### BPE-Dropout"],"metadata":{"id":"ds8e1c_fDC3W"}},{"cell_type":"code","source":["# change working directory\n","os.chdir(f'/content/drive/MyDrive/Research/eng-to-{target_code}/bpeDROP')"],"metadata":{"id":"h_gAAN0WDFBT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mkdir -p trained_model\n","!cp data-bin-25/dict.eng.txt trained_model/dict.eng.txt\n","!cp data-bin-25/dict.tso.txt trained_model/dict.tso.txt\n","!cp /content/drive/MyDrive/Research/eng-to-tso/bpe/data/bpe.codes.4000 trained_model/bpe.codes.4000\n","!cp checkpoints-bpeDROP/checkpoint_best.pt trained_model/model.pt"],"metadata":{"id":"GExgePt7DJxy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!fairseq-interactive \\\n","--path trained_model/model.pt \\\n","--source-lang eng \\\n","--target-lang tso \\\n","--bpe 'subword_nmt' \\\n","--bpe-codes trained_model/bpe.codes.4000 \\\n","--beam 5 \\\n","--lenpen 1 \\\n","--seed 2024 \\\n","--max-len-a 0 \\\n","--max-len-b 100 \\\n","--quiet \\\n","--remove-bpe \\\n","--buffer-size 100 \\\n","--input /content/drive/MyDrive/Research/eng-to-tso/cleaned-data/clean_gtest.eng \\\n","trained_model/ | grep -P \"D-[0-9]+\" | cut -f3 > trained_model/translations_gtest"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EQ5vR-rfDPde","executionInfo":{"status":"ok","timestamp":1730892647043,"user_tz":-120,"elapsed":221196,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"}},"outputId":"64da3c71-514e-4ef3-da73-b65381ac48f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-11-06 11:27:12.736314: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-06 11:27:12.834626: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-06 11:27:12.852981: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-06 11:27:12.894281: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-06 11:27:16.884456: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-11-06 11:27:27 | INFO | fairseq_cli.interactive | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 2024, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'trained_model/model.pt', 'post_process': 'subword_nmt', 'quiet': True, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 100, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 100, 'input': '/content/drive/MyDrive/Research/eng-to-tso/cleaned-data/clean_gtest.eng'}, 'model': None, 'task': {'_name': 'translation', 'data': 'trained_model/', 'source_lang': 'eng', 'target_lang': 'tso', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': {'_name': 'subword_nmt', 'bpe_codes': 'trained_model/bpe.codes.4000', 'bpe_separator': '@@'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2024-11-06 11:27:27 | INFO | fairseq.tasks.translation | [eng] dictionary: 4160 types\n","2024-11-06 11:27:27 | INFO | fairseq.tasks.translation | [tso] dictionary: 4160 types\n","2024-11-06 11:27:27 | INFO | fairseq_cli.interactive | loading model(s) from trained_model/model.pt\n","/content/drive/MyDrive/Research/eng-to-tso/fairseq/fairseq/checkpoint_utils.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state = torch.load(f, map_location=torch.device(\"cpu\"))\n","2024-11-06 11:27:29 | INFO | fairseq_cli.interactive | Sentence buffer size: 100\n","2024-11-06 11:27:29 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n","2024-11-06 11:27:29 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n","2024-11-06 11:27:29 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:27:29 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:27:29 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:27:29 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:27:57 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:27:57 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:27:57 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:27:57 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:28:40 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:28:40 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:28:40 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:28:40 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:29:21 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:29:21 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:29:21 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:29:21 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:30:04 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:30:04 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:30:04 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:30:04 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:30:44 | INFO | fairseq_cli.interactive | Total time: 196.441 seconds; translation time: 192.895\n"]}]},{"cell_type":"code","source":["!fairseq-interactive \\\n","--path trained_model/model.pt \\\n","--source-lang eng \\\n","--target-lang tso \\\n","--bpe 'subword_nmt' \\\n","--bpe-codes trained_model/bpe.codes.4000 \\\n","--beam 5 \\\n","--lenpen 1 \\\n","--seed 2024 \\\n","--max-len-a 0 \\\n","--max-len-b 100 \\\n","--quiet \\\n","--remove-bpe \\\n","--buffer-size 100 \\\n","--input /content/drive/MyDrive/Research/eng-to-tso/cleaned-data/test.eng \\\n","trained_model/ | grep -P \"D-[0-9]+\" | cut -f3 > trained_model/translations_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VLhdMalWDTlI","executionInfo":{"status":"ok","timestamp":1730893200581,"user_tz":-120,"elapsed":553544,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"}},"outputId":"fd626635-33ef-436b-98f8-3a0f14fdd42b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-11-06 11:30:49.892408: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-06 11:30:49.919675: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-06 11:30:49.926953: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-06 11:30:49.945240: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-06 11:30:51.434453: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-11-06 11:31:02 | INFO | fairseq_cli.interactive | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 2024, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'trained_model/model.pt', 'post_process': 'subword_nmt', 'quiet': True, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 100, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 100, 'input': '/content/drive/MyDrive/Research/eng-to-tso/cleaned-data/test.eng'}, 'model': None, 'task': {'_name': 'translation', 'data': 'trained_model/', 'source_lang': 'eng', 'target_lang': 'tso', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': {'_name': 'subword_nmt', 'bpe_codes': 'trained_model/bpe.codes.4000', 'bpe_separator': '@@'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2024-11-06 11:31:02 | INFO | fairseq.tasks.translation | [eng] dictionary: 4160 types\n","2024-11-06 11:31:02 | INFO | fairseq.tasks.translation | [tso] dictionary: 4160 types\n","2024-11-06 11:31:02 | INFO | fairseq_cli.interactive | loading model(s) from trained_model/model.pt\n","/content/drive/MyDrive/Research/eng-to-tso/fairseq/fairseq/checkpoint_utils.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state = torch.load(f, map_location=torch.device(\"cpu\"))\n","2024-11-06 11:31:03 | INFO | fairseq_cli.interactive | Sentence buffer size: 100\n","2024-11-06 11:31:03 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n","2024-11-06 11:31:03 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n","2024-11-06 11:31:03 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:31:03 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:31:03 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:31:03 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:31:23 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:31:23 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:31:23 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:31:23 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:31:42 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:31:42 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:31:42 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:31:42 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:32:00 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:32:00 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:32:00 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:32:00 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:32:20 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:32:20 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:32:20 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:32:20 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:32:38 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:32:38 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:32:38 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:32:38 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:32:55 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:32:55 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:32:55 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:32:55 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:33:15 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:33:15 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:33:15 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:33:15 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:33:31 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:33:31 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:33:31 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:33:31 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:33:46 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:33:46 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:33:46 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:33:46 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:34:04 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:34:04 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:34:04 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:34:04 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:34:20 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:34:20 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:34:20 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:34:20 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:34:37 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:34:37 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:34:37 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:34:37 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:34:55 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:34:55 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:34:55 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:34:55 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:35:15 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:35:15 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:35:15 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:35:15 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:35:33 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:35:33 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:35:33 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:35:33 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:35:52 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:35:52 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:35:52 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:35:52 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:36:12 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:36:12 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:36:12 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:36:12 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:36:30 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:36:30 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:36:30 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:36:30 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:36:47 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:36:47 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:36:47 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:36:47 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:37:04 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:37:04 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:37:04 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:37:04 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:37:20 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:37:20 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:37:20 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:37:20 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:37:37 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:37:37 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:37:37 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:37:37 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:37:53 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:37:53 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:37:53 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:37:53 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:38:11 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:38:11 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:38:11 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:38:11 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:38:30 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:38:30 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:38:30 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:38:30 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:38:48 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:38:48 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:38:48 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:38:48 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:39:05 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:39:05 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:39:05 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:39:05 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:39:22 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:39:22 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:39:22 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:39:22 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:39:40 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:39:40 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:39:40 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:39:40 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:39:58 | INFO | fairseq_cli.interactive | Total time: 535.419 seconds; translation time: 525.739\n"]}]},{"cell_type":"code","source":["# change working directory\n","os.chdir(f'/content/drive/MyDrive/Research/eng-to-{target_code}/cleaned-data')"],"metadata":{"id":"njwoEVfhDY1F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/bpeDROP/trained_model/translations_gtest'"],"metadata":{"id":"TZJxKhnFDbL9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# post-processing predictions\n","with open(translations_path, 'r', encoding='utf-8') as f:\n","  segments = f.read().splitlines()\n","\n","for i in range(len(segments)):\n","  segments[i] = remove_whitespace_before(segments[i], before_punc)\n","\n","post_translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/bpeDROP/trained_model/post_process_translations_gtest'\n","with open(post_translations_path, 'w') as f:\n","  for segment in segments:\n","    f.write(segment + '\\n')"],"metadata":{"id":"z-zou-aMDeRv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/bpeDROP/trained_model/translations_test'"],"metadata":{"id":"2zxSBxXQDmML"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# post-processing predictions\n","with open(translations_path, 'r', encoding='utf-8') as f:\n","  segments = f.read().splitlines()\n","\n","for i in range(len(segments)):\n","  segments[i] = remove_whitespace_before(segments[i], before_punc)\n","\n","post_translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/bpeDROP/trained_model/post_process_translations_test'\n","with open(post_translations_path, 'w') as f:\n","  for segment in segments:\n","    f.write(segment + '\\n')"],"metadata":{"id":"UVqL-gXmDmuW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ULM with Subword Regularization"],"metadata":{"id":"LrErSpnu2f4R"}},{"cell_type":"code","source":["# change working directory\n","os.chdir(f'/content/drive/MyDrive/Research/eng-to-{target_code}/ulmSR')"],"metadata":{"id":"jVAggHRZ2si0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mkdir -p trained_model\n","!cp data-bin-25/dict.eng.txt trained_model/dict.eng.txt\n","!cp data-bin-25/dict.tso.txt trained_model/dict.tso.txt\n","!cp /content/drive/MyDrive/Research/eng-to-tso/ulm/data/joint.model trained_model/joint.model\n","!cp checkpoints-ulmSR/checkpoint_best.pt trained_model/model.pt"],"metadata":{"id":"46VPXHRN2uaS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!fairseq-interactive \\\n","--path trained_model/model.pt \\\n","--source-lang eng \\\n","--target-lang tso \\\n","--bpe 'sentencepiece' \\\n","--sentencepiece-model trained_model/joint.model \\\n","--beam 5 \\\n","--lenpen 1 \\\n","--seed 2024 \\\n","--max-len-a 0 \\\n","--max-len-b 100 \\\n","--quiet \\\n","--remove-bpe sentencepiece \\\n","--buffer-size 100 \\\n","--input /content/drive/MyDrive/Research/eng-to-tso/cleaned-data/clean_gtest.eng \\\n","trained_model/ | grep -P \"H-[0-9]+\" | cut -f3 > trained_model/translations_gtest"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t6fVI-5M2y-P","executionInfo":{"status":"ok","timestamp":1730893443754,"user_tz":-120,"elapsed":239617,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"}},"outputId":"96f800dd-da5a-44b4-ace3-63ebab6e8ac0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-11-06 11:40:07.791521: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-06 11:40:07.816556: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-06 11:40:07.823744: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-06 11:40:07.841801: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-06 11:40:09.381211: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-11-06 11:40:23 | INFO | fairseq_cli.interactive | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 2024, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'trained_model/model.pt', 'post_process': 'sentencepiece', 'quiet': True, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 100, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 100, 'input': '/content/drive/MyDrive/Research/eng-to-tso/cleaned-data/clean_gtest.eng'}, 'model': None, 'task': {'_name': 'translation', 'data': 'trained_model/', 'source_lang': 'eng', 'target_lang': 'tso', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': {'_name': 'sentencepiece', 'sentencepiece_model': 'trained_model/joint.model', 'sentencepiece_enable_sampling': False, 'sentencepiece_alpha': None}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2024-11-06 11:40:23 | INFO | fairseq.tasks.translation | [eng] dictionary: 3992 types\n","2024-11-06 11:40:23 | INFO | fairseq.tasks.translation | [tso] dictionary: 3992 types\n","2024-11-06 11:40:23 | INFO | fairseq_cli.interactive | loading model(s) from trained_model/model.pt\n","/content/drive/MyDrive/Research/eng-to-tso/fairseq/fairseq/checkpoint_utils.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state = torch.load(f, map_location=torch.device(\"cpu\"))\n","2024-11-06 11:40:25 | INFO | fairseq_cli.interactive | Sentence buffer size: 100\n","2024-11-06 11:40:25 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n","2024-11-06 11:40:25 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n","2024-11-06 11:40:26 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:40:26 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:40:26 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:40:26 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:40:54 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:40:54 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:40:54 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:40:54 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:41:45 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:41:45 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:41:45 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:41:45 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:42:31 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:42:31 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:42:31 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:42:31 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:43:16 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:43:16 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:43:16 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:43:16 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:44:01 | INFO | fairseq_cli.interactive | Total time: 217.642 seconds; translation time: 212.839\n"]}]},{"cell_type":"code","source":["!fairseq-interactive \\\n","--path trained_model/model.pt \\\n","--source-lang eng \\\n","--target-lang tso \\\n","--bpe 'sentencepiece' \\\n","--sentencepiece-model trained_model/joint.model \\\n","--beam 5 \\\n","--lenpen 1 \\\n","--seed 2024 \\\n","--max-len-a 0 \\\n","--max-len-b 100 \\\n","--quiet \\\n","--remove-bpe sentencepiece \\\n","--buffer-size 100 \\\n","--input /content/drive/MyDrive/Research/eng-to-tso/cleaned-data/test.eng \\\n","trained_model/ | grep -P \"H-[0-9]+\" | cut -f3 > trained_model/translations_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5nadTXvED22N","executionInfo":{"status":"ok","timestamp":1730894046000,"user_tz":-120,"elapsed":602254,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"}},"outputId":"78297541-7d7c-4232-9214-d7379da65cc5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-11-06 11:44:07.283263: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-06 11:44:07.337922: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-06 11:44:07.354619: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-06 11:44:07.392532: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-06 11:44:09.633566: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-11-06 11:44:19 | INFO | fairseq_cli.interactive | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 2024, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'trained_model/model.pt', 'post_process': 'sentencepiece', 'quiet': True, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 100, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 100, 'input': '/content/drive/MyDrive/Research/eng-to-tso/cleaned-data/test.eng'}, 'model': None, 'task': {'_name': 'translation', 'data': 'trained_model/', 'source_lang': 'eng', 'target_lang': 'tso', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': {'_name': 'sentencepiece', 'sentencepiece_model': 'trained_model/joint.model', 'sentencepiece_enable_sampling': False, 'sentencepiece_alpha': None}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2024-11-06 11:44:19 | INFO | fairseq.tasks.translation | [eng] dictionary: 3992 types\n","2024-11-06 11:44:19 | INFO | fairseq.tasks.translation | [tso] dictionary: 3992 types\n","2024-11-06 11:44:19 | INFO | fairseq_cli.interactive | loading model(s) from trained_model/model.pt\n","/content/drive/MyDrive/Research/eng-to-tso/fairseq/fairseq/checkpoint_utils.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state = torch.load(f, map_location=torch.device(\"cpu\"))\n","2024-11-06 11:44:20 | INFO | fairseq_cli.interactive | Sentence buffer size: 100\n","2024-11-06 11:44:20 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n","2024-11-06 11:44:20 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n","2024-11-06 11:44:20 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:44:20 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:44:20 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:44:20 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:44:40 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:44:40 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:44:40 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:44:40 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:45:00 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:45:00 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:45:00 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:45:00 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:45:19 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:45:19 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:45:19 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:45:19 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:45:42 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:45:42 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:45:42 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:45:42 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:46:02 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:46:02 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:46:02 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:46:02 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:46:22 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:46:22 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:46:22 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:46:22 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:46:44 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:46:44 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:46:44 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:46:44 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:47:03 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:47:03 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:47:03 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:47:03 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:47:21 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:47:21 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:47:21 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:47:21 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:47:40 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:47:40 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:47:40 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:47:40 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:47:58 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:47:58 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:47:58 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:47:58 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:48:17 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:48:17 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:48:17 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:48:17 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:48:38 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:48:38 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:48:38 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:48:38 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:48:59 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:48:59 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:48:59 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:48:59 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:49:17 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:49:17 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:49:17 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:49:17 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:49:37 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:49:37 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:49:37 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:49:37 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:49:59 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:49:59 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:49:59 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:49:59 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:50:16 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:50:16 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:50:16 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:50:16 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:50:35 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:50:35 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:50:35 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:50:35 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:50:52 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:50:52 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:50:52 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:50:52 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:51:12 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:51:12 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:51:12 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:51:12 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:51:30 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:51:30 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:51:30 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:51:30 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:51:47 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:51:47 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:51:47 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:51:47 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:52:07 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:52:07 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:52:07 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:52:07 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:52:27 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:52:27 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:52:27 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:52:27 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:52:45 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:52:45 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:52:45 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:52:45 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:53:03 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:53:03 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:53:03 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:53:03 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:53:22 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:53:22 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:53:22 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:53:22 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:53:44 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:53:44 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:53:44 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:53:44 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:54:03 | INFO | fairseq_cli.interactive | Total time: 583.607 seconds; translation time: 574.220\n"]}]},{"cell_type":"code","source":["# change working directory\n","os.chdir(f'/content/drive/MyDrive/Research/eng-to-{target_code}/cleaned-data')"],"metadata":{"id":"KAYHQBgT2339"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/ulmSR/trained_model/translations_gtest'"],"metadata":{"id":"CVhDjHvz27QB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# post-processing predictions\n","with open(translations_path, 'r', encoding='utf-8') as f:\n","  segments = f.read().splitlines()\n","\n","for i in range(len(segments)):\n","  segments[i] = remove_whitespace_before(segments[i], before_punc)\n","\n","post_translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/ulmSR/trained_model/post_process_translations_gtest'\n","with open(post_translations_path, 'w') as f:\n","  for segment in segments:\n","    f.write(segment + '\\n')"],"metadata":{"id":"ZLy2xvmR278P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/ulmSR/trained_model/translations_test'"],"metadata":{"id":"MkAUfTj5EAjQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# post-processing predictions\n","with open(translations_path, 'r', encoding='utf-8') as f:\n","  segments = f.read().splitlines()\n","\n","for i in range(len(segments)):\n","  segments[i] = remove_whitespace_before(segments[i], before_punc)\n","\n","post_translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/ulmSR/trained_model/post_process_translations_test'\n","with open(post_translations_path, 'w') as f:\n","  for segment in segments:\n","    f.write(segment + '\\n')"],"metadata":{"id":"7RAXTzg0EPEW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Task-specific Tokenization"],"metadata":{"id":"yOh9iIRue1wg"}},{"cell_type":"code","source":["# change working directory\n","os.chdir(f'/content/drive/MyDrive/Research/eng-to-{target_code}/target-tok')"],"metadata":{"id":"Sl3H7SzSe5gE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mkdir -p trained_model\n","!cp data-bin-nmt/dict.eng.txt trained_model/dict.eng.txt\n","!cp data-bin-nmt/dict.tso.txt trained_model/dict.tso.txt\n","!cp /content/drive/MyDrive/Research/eng-to-tso/ulm/data/joint.model trained_model/joint.model\n","!cp checkpoints-task-nmt/checkpoint_best.pt trained_model/model.pt"],"metadata":{"id":"sPUYrYAAe-D-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!fairseq-interactive \\\n","--path trained_model/model.pt \\\n","--source-lang eng \\\n","--target-lang tso \\\n","--bpe 'sentencepiece' \\\n","--sentencepiece-model trained_model/joint.model \\\n","--beam 5 \\\n","--lenpen 1 \\\n","--seed 2024 \\\n","--max-len-a 0 \\\n","--max-len-b 100 \\\n","--quiet \\\n","--remove-bpe sentencepiece \\\n","--buffer-size 100 \\\n","--input /content/drive/MyDrive/Research/eng-to-tso/cleaned-data/clean_gtest.eng \\\n","trained_model/ | grep -P \"H-[0-9]+\" | cut -f3 > trained_model/translations_gtest"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vN3Jc52VfBW8","executionInfo":{"status":"ok","timestamp":1730894459449,"user_tz":-120,"elapsed":206083,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"}},"outputId":"70a8cd0c-9982-41e9-b914-0240437c20ff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-11-06 11:57:37.132367: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-06 11:57:37.158400: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-06 11:57:37.165806: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-06 11:57:37.186094: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-06 11:57:38.641172: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-11-06 11:57:50 | INFO | fairseq_cli.interactive | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 2024, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'trained_model/model.pt', 'post_process': 'sentencepiece', 'quiet': True, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 100, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 100, 'input': '/content/drive/MyDrive/Research/eng-to-tso/cleaned-data/clean_gtest.eng'}, 'model': None, 'task': {'_name': 'translation', 'data': 'trained_model/', 'source_lang': 'eng', 'target_lang': 'tso', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': {'_name': 'sentencepiece', 'sentencepiece_model': 'trained_model/joint.model', 'sentencepiece_enable_sampling': False, 'sentencepiece_alpha': None}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2024-11-06 11:57:50 | INFO | fairseq.tasks.translation | [eng] dictionary: 3992 types\n","2024-11-06 11:57:50 | INFO | fairseq.tasks.translation | [tso] dictionary: 3992 types\n","2024-11-06 11:57:50 | INFO | fairseq_cli.interactive | loading model(s) from trained_model/model.pt\n","/content/drive/MyDrive/Research/eng-to-tso/fairseq/fairseq/checkpoint_utils.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state = torch.load(f, map_location=torch.device(\"cpu\"))\n","2024-11-06 11:57:51 | INFO | fairseq_cli.interactive | Sentence buffer size: 100\n","2024-11-06 11:57:51 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n","2024-11-06 11:57:51 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n","2024-11-06 11:57:51 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:57:51 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:57:51 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:57:51 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:58:15 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:58:15 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:58:15 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:58:15 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:58:57 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:58:57 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:58:57 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:58:57 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 11:59:36 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 11:59:36 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 11:59:36 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 11:59:36 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 12:00:18 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 12:00:18 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 12:00:18 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 12:00:18 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 12:00:56 | INFO | fairseq_cli.interactive | Total time: 186.629 seconds; translation time: 183.495\n"]}]},{"cell_type":"code","source":["!fairseq-interactive \\\n","--path trained_model/model.pt \\\n","--source-lang eng \\\n","--target-lang tso \\\n","--bpe 'sentencepiece' \\\n","--sentencepiece-model trained_model/joint.model \\\n","--beam 5 \\\n","--lenpen 1 \\\n","--seed 2024 \\\n","--max-len-a 0 \\\n","--max-len-b 100 \\\n","--quiet \\\n","--remove-bpe sentencepiece \\\n","--buffer-size 100 \\\n","--input /content/drive/MyDrive/Research/eng-to-tso/cleaned-data/test.eng \\\n","trained_model/ | grep -P \"H-[0-9]+\" | cut -f3 > trained_model/translations_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7pXk-x5NEdJT","executionInfo":{"status":"ok","timestamp":1730894959350,"user_tz":-120,"elapsed":499909,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"}},"outputId":"3eb2f5de-9f79-4f30-d7c5-d1e2f14b4a33"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-11-06 12:01:02.536330: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-06 12:01:02.582730: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-06 12:01:02.596304: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-06 12:01:02.634130: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-06 12:01:04.325129: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-11-06 12:01:14 | INFO | fairseq_cli.interactive | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 2024, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'trained_model/model.pt', 'post_process': 'sentencepiece', 'quiet': True, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 100, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 100, 'input': '/content/drive/MyDrive/Research/eng-to-tso/cleaned-data/test.eng'}, 'model': None, 'task': {'_name': 'translation', 'data': 'trained_model/', 'source_lang': 'eng', 'target_lang': 'tso', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': {'_name': 'sentencepiece', 'sentencepiece_model': 'trained_model/joint.model', 'sentencepiece_enable_sampling': False, 'sentencepiece_alpha': None}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2024-11-06 12:01:14 | INFO | fairseq.tasks.translation | [eng] dictionary: 3992 types\n","2024-11-06 12:01:14 | INFO | fairseq.tasks.translation | [tso] dictionary: 3992 types\n","2024-11-06 12:01:14 | INFO | fairseq_cli.interactive | loading model(s) from trained_model/model.pt\n","/content/drive/MyDrive/Research/eng-to-tso/fairseq/fairseq/checkpoint_utils.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state = torch.load(f, map_location=torch.device(\"cpu\"))\n","2024-11-06 12:01:15 | INFO | fairseq_cli.interactive | Sentence buffer size: 100\n","2024-11-06 12:01:15 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n","2024-11-06 12:01:15 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n","2024-11-06 12:01:15 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 12:01:15 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 12:01:15 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 12:01:15 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 12:01:31 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 12:01:31 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 12:01:31 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 12:01:31 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 12:01:47 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 12:01:47 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 12:01:47 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 12:01:47 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 12:02:04 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 12:02:04 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 12:02:04 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 12:02:04 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 12:02:23 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 12:02:23 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 12:02:23 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 12:02:23 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 12:02:39 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 12:02:39 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 12:02:39 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 12:02:39 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 12:02:55 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 12:02:55 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 12:02:55 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 12:02:55 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 12:03:13 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 12:03:13 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 12:03:13 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 12:03:13 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 12:03:27 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 12:03:27 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 12:03:27 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 12:03:27 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 12:03:41 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 12:03:41 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 12:03:41 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 12:03:41 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 12:03:57 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 12:03:57 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 12:03:57 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 12:03:57 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 12:04:10 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 12:04:10 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 12:04:10 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 12:04:10 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 12:04:26 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 12:04:26 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 12:04:26 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 12:04:26 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 12:04:42 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 12:04:42 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 12:04:42 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 12:04:42 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 12:05:00 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 12:05:00 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 12:05:00 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 12:05:00 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 12:05:16 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 12:05:16 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 12:05:16 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 12:05:16 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 12:05:32 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 12:05:32 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 12:05:32 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 12:05:32 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 12:05:51 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 12:05:51 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 12:05:51 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 12:05:51 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 12:06:05 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 12:06:05 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 12:06:05 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 12:06:05 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 12:06:22 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 12:06:22 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 12:06:22 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 12:06:22 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 12:06:37 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 12:06:37 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 12:06:37 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 12:06:37 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 12:06:52 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 12:06:52 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 12:06:52 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 12:06:52 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 12:07:06 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 12:07:06 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 12:07:06 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 12:07:06 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 12:07:21 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 12:07:21 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 12:07:21 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 12:07:21 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 12:07:37 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 12:07:37 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 12:07:37 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 12:07:37 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 12:07:53 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 12:07:53 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 12:07:53 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 12:07:53 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 12:08:08 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 12:08:08 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 12:08:08 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 12:08:08 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 12:08:23 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 12:08:23 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 12:08:23 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 12:08:23 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 12:08:42 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 12:08:42 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 12:08:42 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 12:08:42 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 12:09:00 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 12:09:00 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 12:09:00 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 12:09:00 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 12:09:16 | INFO | fairseq_cli.interactive | Total time: 482.402 seconds; translation time: 472.131\n"]}]},{"cell_type":"code","source":["# change working directory\n","os.chdir(f'/content/drive/MyDrive/Research/eng-to-{target_code}/cleaned-data')"],"metadata":{"id":"6PExwZTefG5n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/target-tok/trained_model/translations_gtest'"],"metadata":{"id":"jEd0pxhWfKOY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# post-processing predictions\n","with open(translations_path, 'r', encoding='utf-8') as f:\n","  segments = f.read().splitlines()\n","\n","for i in range(len(segments)):\n","  segments[i] = remove_whitespace_before(segments[i], before_punc)\n","\n","post_translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/target-tok/trained_model/post_process_translations_gtest'\n","with open(post_translations_path, 'w') as f:\n","  for segment in segments:\n","    f.write(segment + '\\n')"],"metadata":{"id":"oITD02qpfMsL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!sacrebleu ref1.tso ref2.tso ref3.tso ref4.tso -i $translations_path -m bleu --force\n","!sacrebleu ref1.tso ref2.tso ref3.tso ref4.tso -i $post_translations_path -m bleu"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o4VC5HXdfOEO","executionInfo":{"status":"ok","timestamp":1730894960810,"user_tz":-120,"elapsed":1467,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"}},"outputId":"e958f2c3-d1c9-44aa-e8c8-a36f7adfa859"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n"," \"name\": \"BLEU\",\n"," \"score\": 28.8,\n"," \"signature\": \"nrefs:4|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.3\",\n"," \"verbose_score\": \"66.3/38.9/23.1/13.4 (BP = 0.964 ratio = 0.964 hyp_len = 10915 ref_len = 11318)\",\n"," \"nrefs\": \"4\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.4.3\"\n","}\n","\u001b[0m{\n"," \"name\": \"BLEU\",\n"," \"score\": 28.8,\n"," \"signature\": \"nrefs:4|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.3\",\n"," \"verbose_score\": \"66.3/38.9/23.1/13.4 (BP = 0.964 ratio = 0.964 hyp_len = 10915 ref_len = 11318)\",\n"," \"nrefs\": \"4\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.4.3\"\n","}\n","\u001b[0m"]}]},{"cell_type":"code","source":["translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/target-tok/trained_model/translations_test'"],"metadata":{"id":"IAYiMLpzEizF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# post-processing predictions\n","with open(translations_path, 'r', encoding='utf-8') as f:\n","  segments = f.read().splitlines()\n","\n","for i in range(len(segments)):\n","  segments[i] = remove_whitespace_before(segments[i], before_punc)\n","\n","post_translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/target-tok/trained_model/post_process_translations_test'\n","with open(post_translations_path, 'w') as f:\n","  for segment in segments:\n","    f.write(segment + '\\n')"],"metadata":{"id":"ZkcEAJgEEnCH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!sacrebleu test.tso -i $translations_path -m bleu --force\n","!sacrebleu test.tso -i $post_translations_path -m bleu"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6ZtJCnqCEpGE","executionInfo":{"status":"ok","timestamp":1730894961753,"user_tz":-120,"elapsed":946,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"}},"outputId":"8818f6b4-3143-4b7b-b44b-5e73e05539c2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n"," \"name\": \"BLEU\",\n"," \"score\": 35.0,\n"," \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.3\",\n"," \"verbose_score\": \"64.3/43.9/32.1/24.2 (BP = 0.910 ratio = 0.914 hyp_len = 28625 ref_len = 31326)\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.4.3\"\n","}\n","\u001b[0m{\n"," \"name\": \"BLEU\",\n"," \"score\": 35.0,\n"," \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.3\",\n"," \"verbose_score\": \"64.3/43.9/32.1/24.2 (BP = 0.910 ratio = 0.914 hyp_len = 28625 ref_len = 31326)\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.4.3\"\n","}\n","\u001b[0m"]}]}]}