{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMwNj4oP+zhcc35MwbaVwcG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Setting up the notebook"],"metadata":{"id":"gRYPHQyJ2n81"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"n9d_v-M-2ZIt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730921191175,"user_tz":-120,"elapsed":44753,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"}},"outputId":"612702ff-d26c-442a-b044-4d078dcd7a0a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pip==24.0 in /usr/local/lib/python3.10/dist-packages (24.0)\n","\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.10/dist-packages (1.23.5)\n","\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: tensorboardX in /usr/local/lib/python3.10/dist-packages (2.6.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.23.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (24.1)\n","Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n","\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: subword-nmt in /usr/local/lib/python3.10/dist-packages (0.3.8)\n","Requirement already satisfied: mock in /usr/local/lib/python3.10/dist-packages (from subword-nmt) (5.1.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from subword-nmt) (4.66.6)\n","\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\n","\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["# installing packages\n","!pip install pip==24.0\n","!pip install numpy==1.23.5\n","!pip install tensorboardX\n","!pip install subword-nmt\n","!pip install sentencepiece"]},{"cell_type":"code","source":["# importing packages\n","import numpy\n","import os\n","import tensorboardX\n","import sentencepiece as spm"],"metadata":{"id":"-A7kebwS2yxi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# mounting google drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"id":"3Xe4X1q7226i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730896668926,"user_tz":-120,"elapsed":26621,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"}},"outputId":"cc441bb6-0951-44d3-b38e-2a61d6a283aa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["source_code = 'eng'\n","target_code = 'nde'"],"metadata":{"id":"UzLT4biR24Hh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# change working directory\n","os.chdir(f'/content/drive/MyDrive/Research/eng-to-{target_code}')\n","\n","# installing fairseq\n","#!git clone https://github.com/pytorch/fairseq.git\n","%cd fairseq\n","!pip install --editable ./"],"metadata":{"id":"SX20tTVi26QU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730897105290,"user_tz":-120,"elapsed":436370,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"}},"outputId":"66d538dd-39d5-4cf7-8eea-5bfc836028eb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Research/eng-to-nde/fairseq\n","Obtaining file:///content/drive/MyDrive/Research/eng-to-nde/fairseq\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n","  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (1.17.1)\n","Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (3.0.11)\n","Collecting hydra-core<1.1,>=1.0.7 (from fairseq==0.12.2)\n","  Downloading hydra_core-1.0.7-py3-none-any.whl.metadata (3.7 kB)\n","Collecting omegaconf<2.1 (from fairseq==0.12.2)\n","  Downloading omegaconf-2.0.6-py3-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: numpy>=1.21.3 in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (1.23.5)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (2024.9.11)\n","Collecting sacrebleu>=1.4.12 (from fairseq==0.12.2)\n","  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (2.5.0+cu121)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (4.66.6)\n","Collecting bitarray (from fairseq==0.12.2)\n","  Downloading bitarray-3.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (32 kB)\n","Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (2.5.0+cu121)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (1.5.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (24.1)\n","Collecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq==0.12.2)\n","  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq==0.12.2) (6.0.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq==0.12.2) (4.12.2)\n","Collecting portalocker (from sacrebleu>=1.4.12->fairseq==0.12.2)\n","  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.2) (0.9.0)\n","Collecting colorama (from sacrebleu>=1.4.12->fairseq==0.12.2)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.2) (5.3.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (3.16.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13->fairseq==0.12.2) (1.3.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq==0.12.2) (2.22)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fairseq==0.12.2) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fairseq==0.12.2) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fairseq==0.12.2) (3.5.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->fairseq==0.12.2) (3.0.2)\n","Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n","Downloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bitarray-3.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (278 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.3/278.3 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n","Building wheels for collected packages: fairseq, antlr4-python3-runtime\n","  Building editable for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fairseq: filename=fairseq-0.12.2-0.editable-cp310-cp310-linux_x86_64.whl size=9580 sha256=8d0c526e6719ebcf8379385d6ea8c041da82cbae8e840ca6b05484ccb7542469\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-8p5viqpj/wheels/6d/32/b1/3485300f1dfb18e111b31c9cbe05a78b321fd1cad4955962ea\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141214 sha256=bf4f4452fbf1b851053e3629613623982d2669748876add6d8bc6a94492a9200\n","  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n","Successfully built fairseq antlr4-python3-runtime\n","\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0mInstalling collected packages: bitarray, antlr4-python3-runtime, portalocker, omegaconf, colorama, sacrebleu, hydra-core, fairseq\n","Successfully installed antlr4-python3-runtime-4.8 bitarray-3.0.0 colorama-0.4.6 fairseq-0.12.2 hydra-core-1.0.7 omegaconf-2.0.6 portalocker-2.10.1 sacrebleu-2.4.3\n"]}]},{"cell_type":"markdown","source":["## Evaluate Model on Raw Test and Global Test Sets"],"metadata":{"id":"FuS41Dcr3Zr9"}},{"cell_type":"code","source":["import sacrebleu"],"metadata":{"id":"--J-hIdBjHwv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["before_punc = '!,.:;?)'\n","def remove_whitespace_before(segment, punc):\n","  \"\"\"\n","  This function looks for punctuation in a segment and removes the whitespace\n","  before the punctuation mark.\n","\n","  Args:\n","    segment (str): segment to be processed.\n","    punc (str): string of punctuation marks.\n","\n","  Returns:\n","    The segment with whitespace removed before punctuation marks in punc.\n","  \"\"\"\n","  punc_positions = []\n","  for i, symbol in enumerate(segment):\n","    if symbol in punc:\n","      punc_positions.append(i)\n","\n","  punc_positions.reverse()\n","  for pos in punc_positions:\n","    if segment[pos-1] == \" \":\n","      segment = segment[0:pos-1] + segment[pos:]\n","\n","  return segment"],"metadata":{"id":"_6QHpOY6kjMp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### BPE"],"metadata":{"id":"_DwfMJ5G3ea-"}},{"cell_type":"code","source":["# change working directory\n","os.chdir(f'/content/drive/MyDrive/Research/eng-to-{target_code}/bpe')"],"metadata":{"id":"JgLGxEbADw75"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mkdir -p trained_model\n","!cp data-bin/dict.eng.txt trained_model/dict.eng.txt\n","!cp data-bin/dict.nde.txt trained_model/dict.nde.txt\n","!cp data/bpe.codes.4000 trained_model/bpe.codes.4000\n","!cp checkpoints-bpe/checkpoint_best.pt trained_model/model.pt"],"metadata":{"id":"FIgSPIZOFR6a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!fairseq-interactive \\\n","--path trained_model/model.pt \\\n","--source-lang eng \\\n","--target-lang nde \\\n","--bpe 'subword_nmt' \\\n","--bpe-codes trained_model/bpe.codes.4000 \\\n","--beam 5 \\\n","--lenpen 1 \\\n","--seed 2024 \\\n","--max-len-a 0 \\\n","--max-len-b 100 \\\n","--quiet \\\n","--remove-bpe \\\n","--buffer-size 100 \\\n","--input /content/drive/MyDrive/Research/eng-to-nde/cleaned-data/clean_gtest.eng \\\n","trained_model/ | grep -P \"D-[0-9]+\" | cut -f3 > trained_model/translations_gtest"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yoYP9oQhD2vr","executionInfo":{"status":"ok","timestamp":1730898545770,"user_tz":-120,"elapsed":197009,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"}},"outputId":"ace32957-919a-4aeb-d905-111fe92c33ed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-11-06 13:05:51.256124: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-06 13:05:51.280661: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-06 13:05:51.287741: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-06 13:05:51.305774: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-06 13:05:52.764021: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-11-06 13:06:03 | INFO | fairseq_cli.interactive | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 2024, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'trained_model/model.pt', 'post_process': 'subword_nmt', 'quiet': True, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 100, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 100, 'input': '/content/drive/MyDrive/Research/eng-to-nde/cleaned-data/clean_gtest.eng'}, 'model': None, 'task': {'_name': 'translation', 'data': 'trained_model/', 'source_lang': 'eng', 'target_lang': 'nde', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': {'_name': 'subword_nmt', 'bpe_codes': 'trained_model/bpe.codes.4000', 'bpe_separator': '@@'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2024-11-06 13:06:03 | INFO | fairseq.tasks.translation | [eng] dictionary: 4168 types\n","2024-11-06 13:06:03 | INFO | fairseq.tasks.translation | [nde] dictionary: 4168 types\n","2024-11-06 13:06:03 | INFO | fairseq_cli.interactive | loading model(s) from trained_model/model.pt\n","/content/drive/MyDrive/Research/eng-to-nde/fairseq/fairseq/checkpoint_utils.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state = torch.load(f, map_location=torch.device(\"cpu\"))\n","2024-11-06 13:06:04 | INFO | fairseq_cli.interactive | Sentence buffer size: 100\n","2024-11-06 13:06:04 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n","2024-11-06 13:06:04 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n","2024-11-06 13:06:04 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:06:04 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:06:04 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:06:04 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:06:29 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:06:29 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:06:29 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:06:29 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:07:10 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:07:10 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:07:10 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:07:10 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:07:48 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:07:48 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:07:48 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:07:48 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:08:27 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:08:27 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:08:27 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:08:27 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:09:02 | INFO | fairseq_cli.interactive | Total time: 179.136 seconds; translation time: 175.837\n"]}]},{"cell_type":"code","source":["!fairseq-interactive \\\n","--path trained_model/model.pt \\\n","--source-lang eng \\\n","--target-lang nde \\\n","--bpe 'subword_nmt' \\\n","--bpe-codes trained_model/bpe.codes.4000 \\\n","--beam 5 \\\n","--lenpen 1 \\\n","--seed 2024 \\\n","--max-len-a 0 \\\n","--max-len-b 100 \\\n","--quiet \\\n","--remove-bpe \\\n","--buffer-size 100 \\\n","--input /content/drive/MyDrive/Research/eng-to-nde/cleaned-data/test.eng \\\n","trained_model/ | grep -P \"D-[0-9]+\" | cut -f3 > trained_model/translations_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dAhFszuVZ9Ar","executionInfo":{"status":"ok","timestamp":1730899464470,"user_tz":-120,"elapsed":918704,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"}},"outputId":"9a56b546-ce87-410e-fd9f-7ca82261506d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-11-06 13:09:08.139529: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-06 13:09:08.167119: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-06 13:09:08.176185: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-06 13:09:08.195454: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-06 13:09:09.598599: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-11-06 13:09:21 | INFO | fairseq_cli.interactive | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 2024, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'trained_model/model.pt', 'post_process': 'subword_nmt', 'quiet': True, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 100, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 100, 'input': '/content/drive/MyDrive/Research/eng-to-nde/cleaned-data/test.eng'}, 'model': None, 'task': {'_name': 'translation', 'data': 'trained_model/', 'source_lang': 'eng', 'target_lang': 'nde', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': {'_name': 'subword_nmt', 'bpe_codes': 'trained_model/bpe.codes.4000', 'bpe_separator': '@@'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2024-11-06 13:09:21 | INFO | fairseq.tasks.translation | [eng] dictionary: 4168 types\n","2024-11-06 13:09:21 | INFO | fairseq.tasks.translation | [nde] dictionary: 4168 types\n","2024-11-06 13:09:21 | INFO | fairseq_cli.interactive | loading model(s) from trained_model/model.pt\n","/content/drive/MyDrive/Research/eng-to-nde/fairseq/fairseq/checkpoint_utils.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state = torch.load(f, map_location=torch.device(\"cpu\"))\n","2024-11-06 13:09:22 | INFO | fairseq_cli.interactive | Sentence buffer size: 100\n","2024-11-06 13:09:22 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n","2024-11-06 13:09:22 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n","2024-11-06 13:09:22 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:09:22 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:09:22 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:09:22 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:09:51 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:09:51 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:09:51 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:09:51 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:10:21 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:10:21 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:10:21 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:10:21 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:10:50 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:10:50 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:10:50 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:10:50 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:11:17 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:11:17 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:11:17 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:11:17 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:11:51 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:11:51 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:11:51 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:11:51 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:12:20 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:12:20 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:12:20 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:12:20 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:12:50 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:12:50 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:12:50 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:12:50 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:13:20 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:13:20 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:13:20 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:13:20 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:13:50 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:13:50 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:13:50 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:13:50 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:14:20 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:14:20 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:14:20 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:14:20 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:14:48 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:14:48 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:14:48 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:14:48 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:15:20 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:15:20 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:15:20 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:15:20 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:15:53 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:15:53 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:15:53 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:15:53 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:16:20 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:16:20 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:16:20 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:16:20 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:16:53 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:16:53 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:16:53 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:16:53 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:17:23 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:17:23 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:17:23 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:17:23 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:17:51 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:17:51 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:17:51 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:17:51 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:18:20 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:18:20 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:18:20 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:18:20 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:18:51 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:18:51 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:18:51 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:18:51 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:19:20 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:19:20 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:19:20 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:19:20 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:19:49 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:19:49 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:19:49 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:19:49 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:20:21 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:20:21 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:20:21 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:20:21 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:20:50 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:20:50 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:20:50 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:20:50 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:21:20 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:21:20 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:21:20 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:21:20 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:21:54 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:21:54 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:21:54 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:21:54 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:22:25 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:22:25 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:22:25 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:22:25 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:22:54 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:22:54 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:22:54 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:22:54 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:23:22 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:23:22 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:23:22 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:23:22 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:23:51 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:23:51 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:23:51 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:23:51 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:24:22 | INFO | fairseq_cli.interactive | Total time: 900.712 seconds; translation time: 887.627\n"]}]},{"cell_type":"code","source":["# change working directory\n","os.chdir(f'/content/drive/MyDrive/Research/eng-to-{target_code}/cleaned-data')"],"metadata":{"id":"aohCLVVYEJzP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/bpe/trained_model/translations_gtest'"],"metadata":{"id":"2fZqNykwEUSB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# post-processing predictions\n","with open(translations_path, 'r', encoding='utf-8') as f:\n","  segments = f.read().splitlines()\n","\n","for i in range(len(segments)):\n","  segments[i] = remove_whitespace_before(segments[i], before_punc)\n","\n","post_translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/bpe/trained_model/post_process_translations_gtest'\n","with open(post_translations_path, 'w') as f:\n","  for segment in segments:\n","    f.write(segment + '\\n')"],"metadata":{"id":"jlPugTCJEZqn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/bpe/trained_model/translations_test'"],"metadata":{"id":"V6Fp_PunaEko"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# post-processing predictions\n","with open(translations_path, 'r', encoding='utf-8') as f:\n","  segments = f.read().splitlines()\n","\n","for i in range(len(segments)):\n","  segments[i] = remove_whitespace_before(segments[i], before_punc)\n","\n","post_translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/bpe/trained_model/post_process_translations_test'\n","with open(post_translations_path, 'w') as f:\n","  for segment in segments:\n","    f.write(segment + '\\n')"],"metadata":{"id":"nUi4L38raJfH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ULM"],"metadata":{"id":"iauZD-uv3f_U"}},{"cell_type":"code","source":["# change working directory\n","os.chdir(f'/content/drive/MyDrive/Research/eng-to-{target_code}/ulm')"],"metadata":{"id":"enHL8Yr7E-YQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mkdir -p trained_model\n","!cp data-bin/dict.eng.txt trained_model/dict.eng.txt\n","!cp data-bin/dict.nde.txt trained_model/dict.nde.txt\n","!cp data/joint.model trained_model/joint.model\n","!cp checkpoints-ulm/checkpoint_best.pt trained_model/model.pt"],"metadata":{"id":"Ve2z0uigXtBX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!fairseq-interactive \\\n","--path trained_model/model.pt \\\n","--source-lang eng \\\n","--target-lang nde \\\n","--bpe 'sentencepiece' \\\n","--sentencepiece-model trained_model/joint.model \\\n","--beam 5 \\\n","--lenpen 1 \\\n","--seed 2024 \\\n","--max-len-a 0 \\\n","--max-len-b 100 \\\n","--quiet \\\n","--remove-bpe sentencepiece \\\n","--buffer-size 100 \\\n","--input /content/drive/MyDrive/Research/eng-to-nde/cleaned-data/clean_gtest.eng \\\n","trained_model/ | grep -P \"H-[0-9]+\" | cut -f3 > trained_model/translations_gtest"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yXQ1DtgRFFWk","executionInfo":{"status":"ok","timestamp":1730907216885,"user_tz":-120,"elapsed":197505,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"}},"outputId":"e5840e8d-774c-4ea2-9506-bb9437de1a09"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-11-06 15:30:21.684007: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-06 15:30:21.710180: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-06 15:30:21.721659: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-06 15:30:21.743133: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-06 15:30:23.135292: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-11-06 15:30:34 | INFO | fairseq_cli.interactive | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 2024, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'trained_model/model.pt', 'post_process': 'sentencepiece', 'quiet': True, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 100, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 100, 'input': '/content/drive/MyDrive/Research/eng-to-nde/cleaned-data/clean_gtest.eng'}, 'model': None, 'task': {'_name': 'translation', 'data': 'trained_model/', 'source_lang': 'eng', 'target_lang': 'nde', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': {'_name': 'sentencepiece', 'sentencepiece_model': 'trained_model/joint.model', 'sentencepiece_enable_sampling': False, 'sentencepiece_alpha': None}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2024-11-06 15:30:34 | INFO | fairseq.tasks.translation | [eng] dictionary: 3992 types\n","2024-11-06 15:30:34 | INFO | fairseq.tasks.translation | [nde] dictionary: 3992 types\n","2024-11-06 15:30:34 | INFO | fairseq_cli.interactive | loading model(s) from trained_model/model.pt\n","/content/drive/MyDrive/Research/eng-to-nde/fairseq/fairseq/checkpoint_utils.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state = torch.load(f, map_location=torch.device(\"cpu\"))\n","2024-11-06 15:30:34 | INFO | fairseq_cli.interactive | Sentence buffer size: 100\n","2024-11-06 15:30:34 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n","2024-11-06 15:30:34 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n","2024-11-06 15:30:34 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 15:30:34 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 15:30:34 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 15:30:34 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 15:31:00 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 15:31:00 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 15:31:00 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 15:31:00 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 15:31:39 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 15:31:39 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 15:31:39 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 15:31:39 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 15:32:18 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 15:32:18 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 15:32:18 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 15:32:18 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 15:32:57 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 15:32:57 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 15:32:57 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 15:32:57 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 15:33:34 | INFO | fairseq_cli.interactive | Total time: 180.277 seconds; translation time: 177.836\n"]}]},{"cell_type":"code","source":["!fairseq-interactive \\\n","--path trained_model/model.pt \\\n","--source-lang eng \\\n","--target-lang nde \\\n","--bpe 'sentencepiece' \\\n","--sentencepiece-model trained_model/joint.model \\\n","--beam 5 \\\n","--lenpen 1 \\\n","--seed 2024 \\\n","--max-len-a 0 \\\n","--max-len-b 100 \\\n","--quiet \\\n","--remove-bpe sentencepiece \\\n","--buffer-size 100 \\\n","--input /content/drive/MyDrive/Research/eng-to-nde/cleaned-data/test.eng \\\n","trained_model/ | grep -P \"H-[0-9]+\" | cut -f3 > trained_model/translations_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k731BegdbWDl","executionInfo":{"status":"ok","timestamp":1730908103098,"user_tz":-120,"elapsed":886229,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"}},"outputId":"8d35987a-f250-46a2-c9c7-18cb8639ecc7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-11-06 15:33:39.022456: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-06 15:33:39.047216: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-06 15:33:39.054484: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-06 15:33:39.072485: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-06 15:33:40.404681: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-11-06 15:33:50 | INFO | fairseq_cli.interactive | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 2024, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'trained_model/model.pt', 'post_process': 'sentencepiece', 'quiet': True, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 100, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 100, 'input': '/content/drive/MyDrive/Research/eng-to-nde/cleaned-data/test.eng'}, 'model': None, 'task': {'_name': 'translation', 'data': 'trained_model/', 'source_lang': 'eng', 'target_lang': 'nde', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': {'_name': 'sentencepiece', 'sentencepiece_model': 'trained_model/joint.model', 'sentencepiece_enable_sampling': False, 'sentencepiece_alpha': None}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2024-11-06 15:33:50 | INFO | fairseq.tasks.translation | [eng] dictionary: 3992 types\n","2024-11-06 15:33:50 | INFO | fairseq.tasks.translation | [nde] dictionary: 3992 types\n","2024-11-06 15:33:50 | INFO | fairseq_cli.interactive | loading model(s) from trained_model/model.pt\n","/content/drive/MyDrive/Research/eng-to-nde/fairseq/fairseq/checkpoint_utils.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state = torch.load(f, map_location=torch.device(\"cpu\"))\n","2024-11-06 15:33:51 | INFO | fairseq_cli.interactive | Sentence buffer size: 100\n","2024-11-06 15:33:51 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n","2024-11-06 15:33:51 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n","2024-11-06 15:33:51 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 15:33:51 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 15:33:51 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 15:33:51 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 15:34:19 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 15:34:19 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 15:34:19 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 15:34:19 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 15:34:48 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 15:34:48 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 15:34:48 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 15:34:48 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 15:35:16 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 15:35:16 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 15:35:16 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 15:35:16 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 15:35:43 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 15:35:43 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 15:35:43 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 15:35:43 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 15:36:14 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 15:36:14 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 15:36:14 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 15:36:14 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 15:36:43 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 15:36:43 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 15:36:43 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 15:36:43 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 15:37:12 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 15:37:12 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 15:37:12 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 15:37:12 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 15:37:40 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 15:37:40 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 15:37:40 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 15:37:40 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 15:38:11 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 15:38:11 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 15:38:11 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 15:38:11 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 15:38:40 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 15:38:40 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 15:38:40 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 15:38:40 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 15:39:08 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 15:39:08 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 15:39:08 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 15:39:08 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 15:39:37 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 15:39:37 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 15:39:37 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 15:39:37 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 15:40:08 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 15:40:08 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 15:40:08 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 15:40:08 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 15:40:36 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 15:40:36 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 15:40:36 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 15:40:36 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 15:41:06 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 15:41:06 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 15:41:06 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 15:41:06 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 15:41:35 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 15:41:35 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 15:41:35 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 15:41:35 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 15:42:02 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 15:42:02 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 15:42:02 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 15:42:02 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 15:42:30 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 15:42:30 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 15:42:30 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 15:42:30 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 15:43:00 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 15:43:00 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 15:43:00 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 15:43:00 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 15:43:28 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 15:43:28 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 15:43:28 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 15:43:28 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 15:43:56 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 15:43:56 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 15:43:56 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 15:43:56 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 15:44:28 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 15:44:28 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 15:44:28 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 15:44:28 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 15:44:58 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 15:44:58 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 15:44:58 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 15:44:58 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 15:45:26 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 15:45:26 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 15:45:26 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 15:45:26 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 15:45:56 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 15:45:56 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 15:45:56 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 15:45:56 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 15:46:25 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 15:46:25 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 15:46:25 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 15:46:25 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 15:46:54 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 15:46:54 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 15:46:54 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 15:46:54 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 15:47:22 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 15:47:22 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 15:47:22 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 15:47:22 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 15:47:50 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 15:47:50 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 15:47:50 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 15:47:50 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 15:48:20 | INFO | fairseq_cli.interactive | Total time: 869.947 seconds; translation time: 858.061\n"]}]},{"cell_type":"code","source":["# change working directory\n","os.chdir(f'/content/drive/MyDrive/Research/eng-to-{target_code}/cleaned-data')"],"metadata":{"id":"OoR_vcnXLFwc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/ulm/trained_model/translations_gtest'"],"metadata":{"id":"wQy1eV4Jj9cZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# post-processing predictions\n","with open(translations_path, 'r', encoding='utf-8') as f:\n","  segments = f.read().splitlines()\n","\n","for i in range(len(segments)):\n","  segments[i] = remove_whitespace_before(segments[i], before_punc)\n","\n","post_translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/ulm/trained_model/post_process_translations_gtest'\n","with open(post_translations_path, 'w') as f:\n","  for segment in segments:\n","    f.write(segment + '\\n')"],"metadata":{"id":"4A-GlSL6kTiU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!sacrebleu ref1.nde ref2.nde ref3.nde ref4.nde -i $translations_path -m bleu --force\n","!sacrebleu ref1.nde ref2.nde ref3.nde ref4.nde -i $post_translations_path -m bleu"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"auR1RhsFLKL2","executionInfo":{"status":"ok","timestamp":1730908103767,"user_tz":-120,"elapsed":678,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"}},"outputId":"41a416c3-046f-47c7-d81a-da3028bda582"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n"," \"name\": \"BLEU\",\n"," \"score\": 9.6,\n"," \"signature\": \"nrefs:4|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.3\",\n"," \"verbose_score\": \"43.0/16.6/6.6/2.4 (BP = 0.925 ratio = 0.928 hyp_len = 6480 ref_len = 6984)\",\n"," \"nrefs\": \"4\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.4.3\"\n","}\n","\u001b[0m{\n"," \"name\": \"BLEU\",\n"," \"score\": 9.6,\n"," \"signature\": \"nrefs:4|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.3\",\n"," \"verbose_score\": \"43.0/16.6/6.6/2.4 (BP = 0.925 ratio = 0.928 hyp_len = 6480 ref_len = 6984)\",\n"," \"nrefs\": \"4\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.4.3\"\n","}\n","\u001b[0m"]}]},{"cell_type":"code","source":["translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/ulm/trained_model/translations_test'"],"metadata":{"id":"GHljYV3jcAZm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# post-processing predictions\n","with open(translations_path, 'r', encoding='utf-8') as f:\n","  segments = f.read().splitlines()\n","\n","for i in range(len(segments)):\n","  segments[i] = remove_whitespace_before(segments[i], before_punc)\n","\n","post_translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/ulm/trained_model/post_process_translations_test'\n","with open(post_translations_path, 'w') as f:\n","  for segment in segments:\n","    f.write(segment + '\\n')"],"metadata":{"id":"QIPfLRYpcF0M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!sacrebleu test.nde -i $translations_path -m bleu --force\n","!sacrebleu test.nde -i $post_translations_path -m bleu"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SJc247OWcM2_","executionInfo":{"status":"ok","timestamp":1730908105227,"user_tz":-120,"elapsed":1462,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"}},"outputId":"87c7cb79-45b9-4951-d3cd-f34a7c98a76b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n"," \"name\": \"BLEU\",\n"," \"score\": 11.3,\n"," \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.3\",\n"," \"verbose_score\": \"40.7/16.9/8.3/4.1 (BP = 0.908 ratio = 0.912 hyp_len = 37172 ref_len = 40769)\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.4.3\"\n","}\n","\u001b[0m{\n"," \"name\": \"BLEU\",\n"," \"score\": 11.3,\n"," \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.3\",\n"," \"verbose_score\": \"40.7/16.9/8.3/4.1 (BP = 0.908 ratio = 0.912 hyp_len = 37172 ref_len = 40769)\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.4.3\"\n","}\n","\u001b[0m"]}]},{"cell_type":"markdown","source":["### BPE-Dropout"],"metadata":{"id":"wYgfsLq7hNMq"}},{"cell_type":"code","source":["# change working directory\n","os.chdir(f'/content/drive/MyDrive/Research/eng-to-{target_code}/bpeDROP')"],"metadata":{"id":"vf5bUX-1iwIU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mkdir -p trained_model\n","!cp data-bin-25/dict.eng.txt trained_model/dict.eng.txt\n","!cp data-bin-25/dict.nde.txt trained_model/dict.nde.txt\n","!cp /content/drive/MyDrive/Research/eng-to-nde/bpe/data/bpe.codes.4000 trained_model/bpe.codes.4000\n","!cp checkpoints-bpeDROP/checkpoint_best.pt trained_model/model.pt"],"metadata":{"id":"OtKXjzz0i1EI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!fairseq-interactive \\\n","--path trained_model/model.pt \\\n","--source-lang eng \\\n","--target-lang nde \\\n","--bpe 'subword_nmt' \\\n","--bpe-codes trained_model/bpe.codes.4000 \\\n","--beam 5 \\\n","--lenpen 1 \\\n","--seed 2024 \\\n","--max-len-a 0 \\\n","--max-len-b 100 \\\n","--quiet \\\n","--remove-bpe \\\n","--buffer-size 100 \\\n","--input /content/drive/MyDrive/Research/eng-to-nde/cleaned-data/clean_gtest.eng \\\n","trained_model/ | grep -P \"D-[0-9]+\" | cut -f3 > trained_model/translations_gtest"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G_u-j3rRi-jn","executionInfo":{"status":"ok","timestamp":1730899670449,"user_tz":-120,"elapsed":200824,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"}},"outputId":"55b71f24-5910-4588-dd6e-29c93be30e05"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-11-06 13:24:33.230691: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-06 13:24:33.261016: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-06 13:24:33.268518: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-06 13:24:33.286241: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-06 13:24:34.674713: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-11-06 13:24:45 | INFO | fairseq_cli.interactive | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 2024, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'trained_model/model.pt', 'post_process': 'subword_nmt', 'quiet': True, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 100, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 100, 'input': '/content/drive/MyDrive/Research/eng-to-nde/cleaned-data/clean_gtest.eng'}, 'model': None, 'task': {'_name': 'translation', 'data': 'trained_model/', 'source_lang': 'eng', 'target_lang': 'nde', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': {'_name': 'subword_nmt', 'bpe_codes': 'trained_model/bpe.codes.4000', 'bpe_separator': '@@'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2024-11-06 13:24:45 | INFO | fairseq.tasks.translation | [eng] dictionary: 4168 types\n","2024-11-06 13:24:45 | INFO | fairseq.tasks.translation | [nde] dictionary: 4168 types\n","2024-11-06 13:24:45 | INFO | fairseq_cli.interactive | loading model(s) from trained_model/model.pt\n","/content/drive/MyDrive/Research/eng-to-nde/fairseq/fairseq/checkpoint_utils.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state = torch.load(f, map_location=torch.device(\"cpu\"))\n","2024-11-06 13:24:46 | INFO | fairseq_cli.interactive | Sentence buffer size: 100\n","2024-11-06 13:24:46 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n","2024-11-06 13:24:46 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n","2024-11-06 13:24:46 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:24:46 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:24:46 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:24:46 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:25:11 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:25:11 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:25:11 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:25:11 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:25:52 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:25:52 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:25:52 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:25:52 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:26:29 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:26:29 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:26:29 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:26:29 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:27:11 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:27:11 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:27:11 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:27:11 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:27:48 | INFO | fairseq_cli.interactive | Total time: 182.364 seconds; translation time: 179.539\n"]}]},{"cell_type":"code","source":["!fairseq-interactive \\\n","--path trained_model/model.pt \\\n","--source-lang eng \\\n","--target-lang nde \\\n","--bpe 'subword_nmt' \\\n","--bpe-codes trained_model/bpe.codes.4000 \\\n","--beam 5 \\\n","--lenpen 1 \\\n","--seed 2024 \\\n","--max-len-a 0 \\\n","--max-len-b 100 \\\n","--quiet \\\n","--remove-bpe \\\n","--buffer-size 100 \\\n","--input /content/drive/MyDrive/Research/eng-to-nde/cleaned-data/test.eng \\\n","trained_model/ | grep -P \"D-[0-9]+\" | cut -f3 > trained_model/translations_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GhCwAFK2cdSP","executionInfo":{"status":"ok","timestamp":1730900628929,"user_tz":-120,"elapsed":958490,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"}},"outputId":"29fc2899-39f3-4fa9-824e-7e33d0e93cb8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-11-06 13:27:52.822534: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-06 13:27:52.866749: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-06 13:27:52.879494: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-06 13:27:52.909166: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-06 13:27:54.967536: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-11-06 13:28:04 | INFO | fairseq_cli.interactive | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 2024, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'trained_model/model.pt', 'post_process': 'subword_nmt', 'quiet': True, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 100, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 100, 'input': '/content/drive/MyDrive/Research/eng-to-nde/cleaned-data/test.eng'}, 'model': None, 'task': {'_name': 'translation', 'data': 'trained_model/', 'source_lang': 'eng', 'target_lang': 'nde', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': {'_name': 'subword_nmt', 'bpe_codes': 'trained_model/bpe.codes.4000', 'bpe_separator': '@@'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2024-11-06 13:28:04 | INFO | fairseq.tasks.translation | [eng] dictionary: 4168 types\n","2024-11-06 13:28:04 | INFO | fairseq.tasks.translation | [nde] dictionary: 4168 types\n","2024-11-06 13:28:04 | INFO | fairseq_cli.interactive | loading model(s) from trained_model/model.pt\n","/content/drive/MyDrive/Research/eng-to-nde/fairseq/fairseq/checkpoint_utils.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state = torch.load(f, map_location=torch.device(\"cpu\"))\n","2024-11-06 13:28:05 | INFO | fairseq_cli.interactive | Sentence buffer size: 100\n","2024-11-06 13:28:05 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n","2024-11-06 13:28:05 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n","2024-11-06 13:28:05 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:28:05 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:28:05 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:28:05 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:28:35 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:28:35 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:28:35 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:28:35 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:29:06 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:29:06 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:29:06 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:29:06 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:29:36 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:29:36 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:29:36 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:29:36 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:30:05 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:30:05 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:30:05 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:30:05 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:30:37 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:30:37 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:30:37 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:30:37 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:31:07 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:31:07 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:31:07 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:31:07 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:31:38 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:31:38 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:31:38 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:31:38 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:32:11 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:32:11 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:32:11 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:32:11 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:32:43 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:32:43 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:32:43 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:32:43 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:33:14 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:33:14 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:33:14 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:33:14 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:33:45 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:33:45 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:33:45 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:33:45 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:34:17 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:34:17 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:34:17 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:34:17 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:34:52 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:34:52 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:34:52 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:34:52 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:35:21 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:35:21 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:35:21 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:35:21 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:35:54 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:35:54 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:35:54 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:35:54 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:36:24 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:36:24 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:36:24 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:36:24 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:36:53 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:36:53 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:36:53 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:36:53 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:37:26 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:37:26 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:37:26 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:37:26 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:37:57 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:37:57 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:37:57 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:37:57 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:38:28 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:38:28 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:38:28 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:38:28 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:38:59 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:38:59 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:38:59 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:38:59 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:39:34 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:39:34 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:39:34 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:39:34 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:40:07 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:40:07 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:40:07 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:40:07 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:40:38 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:40:38 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:40:38 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:40:38 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:41:10 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:41:10 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:41:10 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:41:10 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:41:41 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:41:41 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:41:41 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:41:41 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:42:13 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:42:13 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:42:13 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:42:13 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:42:44 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:42:44 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:42:44 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:42:44 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:43:14 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:43:14 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:43:14 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:43:14 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:43:46 | INFO | fairseq_cli.interactive | Total time: 941.747 seconds; translation time: 929.532\n"]}]},{"cell_type":"code","source":["# change working directory\n","os.chdir(f'/content/drive/MyDrive/Research/eng-to-{target_code}/cleaned-data')"],"metadata":{"id":"s2tTGyR3jEGn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/bpeDROP/trained_model/translations_gtest'"],"metadata":{"id":"4cpk0w-tjYf8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# post-processing predictions\n","with open(translations_path, 'r', encoding='utf-8') as f:\n","  segments = f.read().splitlines()\n","\n","for i in range(len(segments)):\n","  segments[i] = remove_whitespace_before(segments[i], before_punc)\n","\n","post_translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/bpeDROP/trained_model/post_process_translations_gtest'\n","with open(post_translations_path, 'w') as f:\n","  for segment in segments:\n","    f.write(segment + '\\n')"],"metadata":{"id":"lkI7TmiFliwN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/bpeDROP/trained_model/translations_test'"],"metadata":{"id":"jwePwwjLcquz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# post-processing predictions\n","with open(translations_path, 'r', encoding='utf-8') as f:\n","  segments = f.read().splitlines()\n","\n","for i in range(len(segments)):\n","  segments[i] = remove_whitespace_before(segments[i], before_punc)\n","\n","post_translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/bpeDROP/trained_model/post_process_translations_test'\n","with open(post_translations_path, 'w') as f:\n","  for segment in segments:\n","    f.write(segment + '\\n')"],"metadata":{"id":"YV7OMr2mctDK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!sacrebleu test.nde -i $translations_path -m bleu --force\n","!sacrebleu test.nde -i $post_translations_path -m bleu"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"76aq-tfLcvhj","executionInfo":{"status":"ok","timestamp":1730900631576,"user_tz":-120,"elapsed":1963,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"}},"outputId":"91c26784-8e22-4f49-c3d6-810d19a3794f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n"," \"name\": \"BLEU\",\n"," \"score\": 9.5,\n"," \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.3\",\n"," \"verbose_score\": \"40.0/15.7/7.0/3.1 (BP = 0.876 ratio = 0.883 hyp_len = 35994 ref_len = 40769)\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.4.3\"\n","}\n","\u001b[0m{\n"," \"name\": \"BLEU\",\n"," \"score\": 9.5,\n"," \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.3\",\n"," \"verbose_score\": \"40.0/15.7/7.0/3.1 (BP = 0.876 ratio = 0.883 hyp_len = 35994 ref_len = 40769)\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.4.3\"\n","}\n","\u001b[0m"]}]},{"cell_type":"markdown","source":["### ULM with Subword Regularization"],"metadata":{"id":"JF2F4odghPU7"}},{"cell_type":"code","source":["# change working directory\n","os.chdir(f'/content/drive/MyDrive/Research/eng-to-{target_code}/ulmSR')"],"metadata":{"id":"9hBVCf4WlpVr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mkdir -p trained_model\n","!cp data-bin-25/dict.eng.txt trained_model/dict.eng.txt\n","!cp data-bin-25/dict.nde.txt trained_model/dict.nde.txt\n","!cp /content/drive/MyDrive/Research/eng-to-nde/ulm/data/joint.model trained_model/joint.model\n","!cp checkpoints-ulmSR/checkpoint_best.pt trained_model/model.pt"],"metadata":{"id":"d-K-lBXglur6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!fairseq-interactive \\\n","--path trained_model/model.pt \\\n","--source-lang eng \\\n","--target-lang nde \\\n","--bpe 'sentencepiece' \\\n","--sentencepiece-model trained_model/joint.model \\\n","--beam 5 \\\n","--lenpen 1 \\\n","--seed 2024 \\\n","--max-len-a 0 \\\n","--max-len-b 100 \\\n","--quiet \\\n","--remove-bpe sentencepiece \\\n","--buffer-size 100 \\\n","--input /content/drive/MyDrive/Research/eng-to-nde/cleaned-data/clean_gtest.eng \\\n","trained_model/ | grep -P \"H-[0-9]+\" | cut -f3 > trained_model/translations_gtest"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iPyD5Px-lzNi","executionInfo":{"status":"ok","timestamp":1730921855405,"user_tz":-120,"elapsed":248976,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"}},"outputId":"dae7b38d-c4d1-4e85-d7f1-092832e64191"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-11-06 19:33:31.247757: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-06 19:33:31.293323: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-06 19:33:31.306802: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-06 19:33:31.336926: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-06 19:33:33.000300: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-11-06 19:33:43 | INFO | fairseq_cli.interactive | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 2024, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'trained_model/model.pt', 'post_process': 'sentencepiece', 'quiet': True, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 100, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 100, 'input': '/content/drive/MyDrive/Research/eng-to-nde/cleaned-data/clean_gtest.eng'}, 'model': None, 'task': {'_name': 'translation', 'data': 'trained_model/', 'source_lang': 'eng', 'target_lang': 'nde', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': {'_name': 'sentencepiece', 'sentencepiece_model': 'trained_model/joint.model', 'sentencepiece_enable_sampling': False, 'sentencepiece_alpha': None}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2024-11-06 19:33:43 | INFO | fairseq.tasks.translation | [eng] dictionary: 3992 types\n","2024-11-06 19:33:43 | INFO | fairseq.tasks.translation | [nde] dictionary: 3992 types\n","2024-11-06 19:33:43 | INFO | fairseq_cli.interactive | loading model(s) from trained_model/model.pt\n","/content/drive/MyDrive/Research/eng-to-nde/fairseq/fairseq/checkpoint_utils.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state = torch.load(f, map_location=torch.device(\"cpu\"))\n","2024-11-06 19:33:43 | INFO | fairseq_cli.interactive | Sentence buffer size: 100\n","2024-11-06 19:33:43 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n","2024-11-06 19:33:43 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n","2024-11-06 19:33:44 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 19:33:44 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 19:33:44 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 19:33:44 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 19:34:16 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 19:34:16 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 19:34:16 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 19:34:16 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 19:35:06 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 19:35:06 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 19:35:06 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 19:35:06 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 19:35:54 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 19:35:54 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 19:35:54 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 19:35:54 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 19:36:46 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 19:36:46 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 19:36:46 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 19:36:46 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 19:37:31 | INFO | fairseq_cli.interactive | Total time: 228.707 seconds; translation time: 225.840\n"]}]},{"cell_type":"code","source":["!fairseq-interactive \\\n","--path trained_model/model.pt \\\n","--source-lang eng \\\n","--target-lang nde \\\n","--bpe 'sentencepiece' \\\n","--sentencepiece-model trained_model/joint.model \\\n","--beam 5 \\\n","--lenpen 1 \\\n","--seed 2024 \\\n","--max-len-a 0 \\\n","--max-len-b 100 \\\n","--quiet \\\n","--remove-bpe sentencepiece \\\n","--buffer-size 100 \\\n","--input /content/drive/MyDrive/Research/eng-to-nde/cleaned-data/test.eng \\\n","trained_model/ | grep -P \"H-[0-9]+\" | cut -f3 > trained_model/translations_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-kqlgC0fc6iA","executionInfo":{"status":"ok","timestamp":1730923063050,"user_tz":-120,"elapsed":1207655,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"}},"outputId":"cf71842f-6889-47c9-bb1f-77c1dbb53b64"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-11-06 19:37:37.476406: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-06 19:37:37.518039: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-06 19:37:37.529873: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-06 19:37:37.559526: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-06 19:37:39.211357: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-11-06 19:37:48 | INFO | fairseq_cli.interactive | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 2024, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'trained_model/model.pt', 'post_process': 'sentencepiece', 'quiet': True, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 100, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 100, 'input': '/content/drive/MyDrive/Research/eng-to-nde/cleaned-data/test.eng'}, 'model': None, 'task': {'_name': 'translation', 'data': 'trained_model/', 'source_lang': 'eng', 'target_lang': 'nde', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': {'_name': 'sentencepiece', 'sentencepiece_model': 'trained_model/joint.model', 'sentencepiece_enable_sampling': False, 'sentencepiece_alpha': None}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2024-11-06 19:37:49 | INFO | fairseq.tasks.translation | [eng] dictionary: 3992 types\n","2024-11-06 19:37:49 | INFO | fairseq.tasks.translation | [nde] dictionary: 3992 types\n","2024-11-06 19:37:49 | INFO | fairseq_cli.interactive | loading model(s) from trained_model/model.pt\n","/content/drive/MyDrive/Research/eng-to-nde/fairseq/fairseq/checkpoint_utils.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state = torch.load(f, map_location=torch.device(\"cpu\"))\n","2024-11-06 19:37:49 | INFO | fairseq_cli.interactive | Sentence buffer size: 100\n","2024-11-06 19:37:49 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n","2024-11-06 19:37:49 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n","2024-11-06 19:37:49 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 19:37:49 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 19:37:49 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 19:37:49 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 19:38:28 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 19:38:28 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 19:38:28 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 19:38:28 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 19:39:06 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 19:39:06 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 19:39:06 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 19:39:06 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 19:39:44 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 19:39:44 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 19:39:44 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 19:39:44 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 19:40:19 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 19:40:19 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 19:40:19 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 19:40:19 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 19:41:01 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 19:41:01 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 19:41:01 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 19:41:01 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 19:41:39 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 19:41:39 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 19:41:39 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 19:41:39 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 19:42:19 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 19:42:19 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 19:42:19 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 19:42:19 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 19:43:02 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 19:43:02 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 19:43:02 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 19:43:02 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 19:43:43 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 19:43:43 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 19:43:43 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 19:43:43 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 19:44:23 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 19:44:23 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 19:44:23 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 19:44:23 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 19:45:01 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 19:45:01 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 19:45:01 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 19:45:01 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 19:45:42 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 19:45:42 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 19:45:42 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 19:45:42 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 19:46:25 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 19:46:25 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 19:46:25 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 19:46:25 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 19:47:01 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 19:47:01 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 19:47:01 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 19:47:01 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 19:47:40 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 19:47:40 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 19:47:40 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 19:47:40 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 19:48:21 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 19:48:21 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 19:48:21 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 19:48:21 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 19:48:57 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 19:48:57 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 19:48:57 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 19:48:57 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 19:49:36 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 19:49:36 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 19:49:36 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 19:49:36 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 19:50:14 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 19:50:14 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 19:50:14 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 19:50:14 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 19:50:54 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 19:50:54 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 19:50:54 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 19:50:54 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 19:51:31 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 19:51:31 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 19:51:31 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 19:51:31 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 19:52:18 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 19:52:18 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 19:52:18 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 19:52:18 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 19:52:58 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 19:52:58 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 19:52:58 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 19:52:58 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 19:53:38 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 19:53:38 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 19:53:38 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 19:53:38 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 19:54:19 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 19:54:19 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 19:54:19 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 19:54:19 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 19:55:01 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 19:55:01 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 19:55:01 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 19:55:01 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 19:55:41 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 19:55:41 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 19:55:41 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 19:55:41 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 19:56:19 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 19:56:19 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 19:56:19 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 19:56:19 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 19:56:58 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 19:56:58 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 19:56:58 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 19:56:58 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 19:57:40 | INFO | fairseq_cli.interactive | Total time: 1191.617 seconds; translation time: 1178.748\n"]}]},{"cell_type":"code","source":["# change working directory\n","os.chdir(f'/content/drive/MyDrive/Research/eng-to-{target_code}/cleaned-data')"],"metadata":{"id":"Ty3Hsdcwl2KM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/ulmSR/trained_model/translations_gtest'"],"metadata":{"id":"rznIalbel6gZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# post-processing predictions\n","with open(translations_path, 'r', encoding='utf-8') as f:\n","  segments = f.read().splitlines()\n","\n","for i in range(len(segments)):\n","  segments[i] = remove_whitespace_before(segments[i], before_punc)\n","\n","post_translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/ulmSR/trained_model/post_process_translations_gtest'\n","with open(post_translations_path, 'w') as f:\n","  for segment in segments:\n","    f.write(segment + '\\n')"],"metadata":{"id":"dyxl_42amAjb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/ulmSR/trained_model/translations_test'"],"metadata":{"id":"CxJJGo95dEDM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# post-processing predictions\n","with open(translations_path, 'r', encoding='utf-8') as f:\n","  segments = f.read().splitlines()\n","\n","for i in range(len(segments)):\n","  segments[i] = remove_whitespace_before(segments[i], before_punc)\n","\n","post_translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/ulmSR/trained_model/post_process_translations_test'\n","with open(post_translations_path, 'w') as f:\n","  for segment in segments:\n","    f.write(segment + '\\n')"],"metadata":{"id":"mC8FWM-adHZc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Task-specific Tokenization"],"metadata":{"id":"q_INYt4nYQRM"}},{"cell_type":"code","source":["# change working directory\n","os.chdir(f'/content/drive/MyDrive/Research/eng-to-{target_code}/target-tok')"],"metadata":{"id":"IcUT93FvYYOB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mkdir -p trained_model\n","!cp data-bin-nmt/dict.eng.txt trained_model/dict.eng.txt\n","!cp data-bin-nmt/dict.nde.txt trained_model/dict.nde.txt\n","!cp /content/drive/MyDrive/Research/eng-to-nde/ulm/data/joint.model trained_model/joint.model\n","!cp checkpoints-task-nmt/checkpoint_best.pt trained_model/model.pt"],"metadata":{"id":"QGbPXv9PYY3a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!fairseq-interactive \\\n","--path trained_model/model.pt \\\n","--source-lang eng \\\n","--target-lang nde \\\n","--bpe 'sentencepiece' \\\n","--sentencepiece-model trained_model/joint.model \\\n","--beam 5 \\\n","--lenpen 1 \\\n","--seed 2024 \\\n","--max-len-a 0 \\\n","--max-len-b 100 \\\n","--quiet \\\n","--remove-bpe sentencepiece \\\n","--buffer-size 100 \\\n","--input /content/drive/MyDrive/Research/eng-to-nde/cleaned-data/clean_gtest.eng \\\n","trained_model/ | grep -P \"H-[0-9]+\" | cut -f3 > trained_model/translations_gtest"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FB9I4dMiYfZa","executionInfo":{"status":"ok","timestamp":1730900826675,"user_tz":-120,"elapsed":193870,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"}},"outputId":"bff5679e-972d-40a1-e096-537bae3fa6ca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-11-06 13:43:54.960476: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-06 13:43:54.985439: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-06 13:43:54.992709: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-06 13:43:55.012309: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-06 13:43:56.362278: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-11-06 13:44:07 | INFO | fairseq_cli.interactive | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 2024, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'trained_model/model.pt', 'post_process': 'sentencepiece', 'quiet': True, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 100, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 100, 'input': '/content/drive/MyDrive/Research/eng-to-nde/cleaned-data/clean_gtest.eng'}, 'model': None, 'task': {'_name': 'translation', 'data': 'trained_model/', 'source_lang': 'eng', 'target_lang': 'nde', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': {'_name': 'sentencepiece', 'sentencepiece_model': 'trained_model/joint.model', 'sentencepiece_enable_sampling': False, 'sentencepiece_alpha': None}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2024-11-06 13:44:07 | INFO | fairseq.tasks.translation | [eng] dictionary: 3992 types\n","2024-11-06 13:44:07 | INFO | fairseq.tasks.translation | [nde] dictionary: 3992 types\n","2024-11-06 13:44:07 | INFO | fairseq_cli.interactive | loading model(s) from trained_model/model.pt\n","/content/drive/MyDrive/Research/eng-to-nde/fairseq/fairseq/checkpoint_utils.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state = torch.load(f, map_location=torch.device(\"cpu\"))\n","2024-11-06 13:44:08 | INFO | fairseq_cli.interactive | Sentence buffer size: 100\n","2024-11-06 13:44:08 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n","2024-11-06 13:44:08 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n","2024-11-06 13:44:08 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:44:08 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:44:08 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:44:08 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:44:33 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:44:33 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:44:33 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:44:33 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:45:12 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:45:12 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:45:12 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:45:12 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:45:48 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:45:48 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:45:48 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:45:48 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:46:29 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:46:29 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:46:29 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:46:29 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:47:03 | INFO | fairseq_cli.interactive | Total time: 175.890 seconds; translation time: 173.244\n"]}]},{"cell_type":"code","source":["!fairseq-interactive \\\n","--path trained_model/model.pt \\\n","--source-lang eng \\\n","--target-lang nde \\\n","--bpe 'sentencepiece' \\\n","--sentencepiece-model trained_model/joint.model \\\n","--beam 5 \\\n","--lenpen 1 \\\n","--seed 2024 \\\n","--max-len-a 0 \\\n","--max-len-b 100 \\\n","--quiet \\\n","--remove-bpe sentencepiece \\\n","--buffer-size 100 \\\n","--input /content/drive/MyDrive/Research/eng-to-nde/cleaned-data/test.eng \\\n","trained_model/ | grep -P \"H-[0-9]+\" | cut -f3 > trained_model/translations_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p5omHOxnd1Lj","executionInfo":{"status":"ok","timestamp":1730901744613,"user_tz":-120,"elapsed":917941,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"}},"outputId":"696bfdeb-904a-447c-c357-0b6377c97b71"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-11-06 13:47:09.781781: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-06 13:47:09.806120: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-06 13:47:09.813049: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-06 13:47:09.830306: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-06 13:47:11.194933: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-11-06 13:47:21 | INFO | fairseq_cli.interactive | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 2024, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'trained_model/model.pt', 'post_process': 'sentencepiece', 'quiet': True, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 100, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 100, 'input': '/content/drive/MyDrive/Research/eng-to-nde/cleaned-data/test.eng'}, 'model': None, 'task': {'_name': 'translation', 'data': 'trained_model/', 'source_lang': 'eng', 'target_lang': 'nde', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': {'_name': 'sentencepiece', 'sentencepiece_model': 'trained_model/joint.model', 'sentencepiece_enable_sampling': False, 'sentencepiece_alpha': None}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2024-11-06 13:47:21 | INFO | fairseq.tasks.translation | [eng] dictionary: 3992 types\n","2024-11-06 13:47:21 | INFO | fairseq.tasks.translation | [nde] dictionary: 3992 types\n","2024-11-06 13:47:21 | INFO | fairseq_cli.interactive | loading model(s) from trained_model/model.pt\n","/content/drive/MyDrive/Research/eng-to-nde/fairseq/fairseq/checkpoint_utils.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state = torch.load(f, map_location=torch.device(\"cpu\"))\n","2024-11-06 13:47:22 | INFO | fairseq_cli.interactive | Sentence buffer size: 100\n","2024-11-06 13:47:22 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n","2024-11-06 13:47:22 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n","2024-11-06 13:47:22 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:47:22 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:47:22 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:47:22 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:47:50 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:47:50 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:47:50 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:47:50 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:48:22 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:48:22 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:48:22 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:48:22 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:48:51 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:48:51 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:48:51 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:48:51 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:49:18 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:49:18 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:49:18 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:49:18 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:49:50 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:49:50 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:49:50 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:49:50 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:50:20 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:50:20 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:50:20 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:50:20 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:50:48 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:50:48 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:50:48 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:50:48 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:51:18 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:51:18 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:51:18 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:51:18 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:51:48 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:51:48 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:51:48 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:51:48 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:52:18 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:52:18 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:52:18 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:52:18 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:52:49 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:52:49 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:52:49 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:52:49 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:53:20 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:53:20 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:53:20 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:53:20 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:53:52 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:53:52 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:53:52 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:53:52 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:54:19 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:54:19 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:54:19 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:54:19 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:54:50 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:54:50 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:54:50 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:54:50 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:55:20 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:55:20 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:55:20 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:55:20 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:55:47 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:55:47 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:55:47 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:55:47 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:56:15 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:56:15 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:56:15 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:56:15 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:56:45 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:56:45 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:56:45 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:56:45 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:57:14 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:57:14 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:57:14 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:57:14 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:57:44 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:57:44 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:57:44 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:57:44 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:58:17 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:58:17 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:58:17 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:58:17 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:58:47 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:58:47 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:58:47 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:58:47 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:59:19 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:59:19 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:59:19 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:59:19 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 13:59:51 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 13:59:51 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 13:59:51 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 13:59:51 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 14:00:22 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 14:00:22 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 14:00:22 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 14:00:22 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 14:00:52 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 14:00:52 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 14:00:52 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 14:00:52 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 14:01:21 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 14:01:21 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 14:01:21 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 14:01:21 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 14:01:51 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 14:01:51 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 14:01:51 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 14:01:51 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 14:02:22 | INFO | fairseq_cli.interactive | Total time: 901.085 seconds; translation time: 889.910\n"]}]},{"cell_type":"code","source":["# change working directory\n","os.chdir(f'/content/drive/MyDrive/Research/eng-to-{target_code}/cleaned-data')"],"metadata":{"id":"xSWSMuDkYk1T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/target-tok/trained_model/translations_gtest'"],"metadata":{"id":"ZbfrLPpdYoxH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# post-processing predictions\n","with open(translations_path, 'r', encoding='utf-8') as f:\n","  segments = f.read().splitlines()\n","\n","for i in range(len(segments)):\n","  segments[i] = remove_whitespace_before(segments[i], before_punc)\n","\n","post_translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/target-tok/trained_model/post_process_translations_gtest'\n","with open(post_translations_path, 'w') as f:\n","  for segment in segments:\n","    f.write(segment + '\\n')"],"metadata":{"id":"xHuuUwHkYqri"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/target-tok/trained_model/translations_test'"],"metadata":{"id":"yGvkuEz2pQKw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# post-processing predictions\n","with open(translations_path, 'r', encoding='utf-8') as f:\n","  segments = f.read().splitlines()\n","\n","for i in range(len(segments)):\n","  segments[i] = remove_whitespace_before(segments[i], before_punc)\n","\n","post_translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/target-tok/trained_model/post_process_translations_test'\n","with open(post_translations_path, 'w') as f:\n","  for segment in segments:\n","    f.write(segment + '\\n')"],"metadata":{"id":"0-XmJ8P3Wluq"},"execution_count":null,"outputs":[]}]}