{"cells":[{"cell_type":"markdown","metadata":{"id":"gRYPHQyJ2n81"},"source":["## Setting up the notebook"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34854,"status":"ok","timestamp":1737882048346,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"},"user_tz":-120},"id":"n9d_v-M-2ZIt","outputId":"d87b65d7-3765-424f-9df8-8b97f4c0130e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pip==24.0 in /usr/local/lib/python3.11/dist-packages (24.0)\n","Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.11/dist-packages (1.23.5)\n","Requirement already satisfied: tensorboardX in /usr/local/lib/python3.11/dist-packages (2.6.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (1.23.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (24.2)\n","Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (4.25.5)\n","Collecting subword-nmt\n","  Downloading subword_nmt-0.3.8-py3-none-any.whl.metadata (9.2 kB)\n","Collecting mock (from subword-nmt)\n","  Downloading mock-5.1.0-py3-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from subword-nmt) (4.67.1)\n","Downloading subword_nmt-0.3.8-py3-none-any.whl (27 kB)\n","Downloading mock-5.1.0-py3-none-any.whl (30 kB)\n","Installing collected packages: mock, subword-nmt\n","Successfully installed mock-5.1.0 subword-nmt-0.3.8\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n"]}],"source":["# installing packages\n","!pip install pip==24.0\n","!pip install numpy==1.23.5\n","!pip install tensorboardX\n","!pip install subword-nmt\n","!pip install sentencepiece"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-A7kebwS2yxi"},"outputs":[],"source":["# importing packages\n","import numpy\n","import os\n","import tensorboardX\n","import sentencepiece as spm"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29320,"status":"ok","timestamp":1737882090196,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"},"user_tz":-120},"id":"3Xe4X1q7226i","outputId":"155f8f66-4198-486b-997e-cd8399fff295"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# mounting google drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UzLT4biR24Hh"},"outputs":[],"source":["source_code = 'eng'\n","target_code = 'nso'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SX20tTVi26QU","executionInfo":{"status":"ok","timestamp":1737882524468,"user_tz":-120,"elapsed":434276,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"}},"outputId":"2dc63956-ce7f-41ed-ad80-1ffefb8d1eee"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Research/eng-to-nso/fairseq\n","Obtaining file:///content/drive/MyDrive/Research/eng-to-nso/fairseq\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n","  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: cffi in /usr/local/lib/python3.11/dist-packages (from fairseq==0.12.2) (1.17.1)\n","Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (from fairseq==0.12.2) (3.0.11)\n","Collecting hydra-core<1.1,>=1.0.7 (from fairseq==0.12.2)\n","  Downloading hydra_core-1.0.7-py3-none-any.whl.metadata (3.7 kB)\n","Collecting omegaconf<2.1 (from fairseq==0.12.2)\n","  Downloading omegaconf-2.0.6-py3-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: numpy>=1.21.3 in /usr/local/lib/python3.11/dist-packages (from fairseq==0.12.2) (1.23.5)\n","Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from fairseq==0.12.2) (2024.11.6)\n","Collecting sacrebleu>=1.4.12 (from fairseq==0.12.2)\n","  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.13 in /usr/local/lib/python3.11/dist-packages (from fairseq==0.12.2) (2.5.1+cu121)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from fairseq==0.12.2) (4.67.1)\n","Collecting bitarray (from fairseq==0.12.2)\n","  Downloading bitarray-3.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (32 kB)\n","Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from fairseq==0.12.2) (2.5.1+cu121)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from fairseq==0.12.2) (1.6.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from fairseq==0.12.2) (24.2)\n","Collecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq==0.12.2)\n","  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.11/dist-packages (from omegaconf<2.1->fairseq==0.12.2) (6.0.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from omegaconf<2.1->fairseq==0.12.2) (4.12.2)\n","Collecting portalocker (from sacrebleu>=1.4.12->fairseq==0.12.2)\n","  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.2) (0.9.0)\n","Collecting colorama (from sacrebleu>=1.4.12->fairseq==0.12.2)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.2) (5.3.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->fairseq==0.12.2) (3.17.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->fairseq==0.12.2) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->fairseq==0.12.2) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->fairseq==0.12.2) (2024.10.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->fairseq==0.12.2) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->fairseq==0.12.2) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->fairseq==0.12.2) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->fairseq==0.12.2) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->fairseq==0.12.2) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->fairseq==0.12.2) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->fairseq==0.12.2) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->fairseq==0.12.2) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->fairseq==0.12.2) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->fairseq==0.12.2) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->fairseq==0.12.2) (12.1.105)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->fairseq==0.12.2) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->fairseq==0.12.2) (1.13.1)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13->fairseq==0.12.2) (12.6.85)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13->fairseq==0.12.2) (1.3.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi->fairseq==0.12.2) (2.22)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->fairseq==0.12.2) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->fairseq==0.12.2) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->fairseq==0.12.2) (3.5.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13->fairseq==0.12.2) (3.0.2)\n","Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n","Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bitarray-3.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (286 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n","Building wheels for collected packages: fairseq, antlr4-python3-runtime\n","  Building editable for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fairseq: filename=fairseq-0.12.2-0.editable-cp311-cp311-linux_x86_64.whl size=9619 sha256=b24fb4e1c068a5fd44a7e7886c4a27ef135977524afe58506607f66715bc666c\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-cduodlz_/wheels/a5/ee/3f/53096fcc640607d78757d49265ff79b6fba9afdc74e4952244\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141214 sha256=2587ecc8c80410dc2cbe450b3b52295b9d9ea252dfed56dc126692cf49bc3fa2\n","  Stored in directory: /root/.cache/pip/wheels/21/10/be/9a70640a3a60ed4a7e1a45e49bb9f58b04692d5d7b517bd39e\n","Successfully built fairseq antlr4-python3-runtime\n","\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0mInstalling collected packages: bitarray, antlr4-python3-runtime, portalocker, omegaconf, colorama, sacrebleu, hydra-core, fairseq\n","Successfully installed antlr4-python3-runtime-4.8 bitarray-3.0.0 colorama-0.4.6 fairseq-0.12.2 hydra-core-1.0.7 omegaconf-2.0.6 portalocker-3.1.1 sacrebleu-2.5.1\n"]}],"source":["# change working directory\n","os.chdir(f'/content/drive/MyDrive/Research/eng-to-{target_code}')\n","\n","# installing fairseq\n","#!git clone https://github.com/pytorch/fairseq.git\n","%cd fairseq\n","!pip install --editable ./"]},{"cell_type":"markdown","metadata":{"id":"FuS41Dcr3Zr9"},"source":["## Evaluate Model on Raw Test and Global Test Sets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6lFbRni-_nEe"},"outputs":[],"source":["import sacrebleu"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nZUcGkgs_ndi"},"outputs":[],"source":["before_punc = '!,.:;?)'\n","def remove_whitespace_before(segment, punc):\n","  \"\"\"\n","  This function looks for punctuation in a segment and removes the whitespace\n","  before the punctuation mark.\n","\n","  Args:\n","    segment (str): segment to be processed.\n","    punc (str): string of punctuation marks.\n","\n","  Returns:\n","    The segment with whitespace removed before punctuation marks in punc.\n","  \"\"\"\n","  punc_positions = []\n","  for i, symbol in enumerate(segment):\n","    if symbol in punc:\n","      punc_positions.append(i)\n","\n","  punc_positions.reverse()\n","  for pos in punc_positions:\n","    if segment[pos-1] == \" \":\n","      segment = segment[0:pos-1] + segment[pos:]\n","\n","  return segment"]},{"cell_type":"markdown","metadata":{"id":"_DwfMJ5G3ea-"},"source":["### BPE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JgLGxEbADw75"},"outputs":[],"source":["# change working directory\n","os.chdir(f'/content/drive/MyDrive/Research/eng-to-{target_code}/bpe')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FIgSPIZOFR6a"},"outputs":[],"source":["!mkdir -p trained_model\n","!cp data-bin/dict.eng.txt trained_model/dict.eng.txt\n","!cp data-bin/dict.nso.txt trained_model/dict.nso.txt\n","!cp data/bpe.codes.4000 trained_model/bpe.codes.4000\n","!cp checkpoints-bpe/checkpoint_best.pt trained_model/model.pt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2999,"status":"ok","timestamp":1737882842908,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"},"user_tz":-120},"id":"yoYP9oQhD2vr","outputId":"f3d063ad-5ec4-4258-aa10-4dd0f7aee966"},"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/usr/local/bin/fairseq-interactive\", line 5, in <module>\n","    from fairseq_cli.interactive import cli_main\n","  File \"/content/drive/MyDrive/Research/eng-to-nso/fairseq/fairseq_cli/interactive.py\", line 23, in <module>\n","    from fairseq import checkpoint_utils, distributed_utils, options, tasks, utils\n","  File \"/content/drive/MyDrive/Research/eng-to-nso/fairseq/fairseq/__init__.py\", line 20, in <module>\n","    from fairseq.distributed import utils as distributed_utils\n","  File \"/content/drive/MyDrive/Research/eng-to-nso/fairseq/fairseq/distributed/__init__.py\", line 7, in <module>\n","    from .fully_sharded_data_parallel import (\n","  File \"/content/drive/MyDrive/Research/eng-to-nso/fairseq/fairseq/distributed/fully_sharded_data_parallel.py\", line 10, in <module>\n","    from fairseq.dataclass.configs import DistributedTrainingConfig\n","  File \"/content/drive/MyDrive/Research/eng-to-nso/fairseq/fairseq/dataclass/__init__.py\", line 6, in <module>\n","    from .configs import FairseqDataclass\n","  File \"/content/drive/MyDrive/Research/eng-to-nso/fairseq/fairseq/dataclass/configs.py\", line 1127, in <module>\n","    @dataclass\n","     ^^^^^^^^^\n","  File \"/usr/lib/python3.11/dataclasses.py\", line 1232, in dataclass\n","    return wrap(cls)\n","           ^^^^^^^^^\n","  File \"/usr/lib/python3.11/dataclasses.py\", line 1222, in wrap\n","    return _process_class(cls, init, repr, eq, order, unsafe_hash,\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/dataclasses.py\", line 958, in _process_class\n","    cls_fields.append(_get_field(cls, name, type, kw_only))\n","                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/dataclasses.py\", line 815, in _get_field\n","    raise ValueError(f'mutable default {type(f.default)} for field '\n","ValueError: mutable default <class 'fairseq.dataclass.configs.CommonConfig'> for field common is not allowed: use default_factory\n"]}],"source":["!fairseq-interactive \\\n","--path trained_model/model.pt \\\n","--source-lang eng \\\n","--target-lang nso \\\n","--bpe 'subword_nmt' \\\n","--bpe-codes trained_model/bpe.codes.4000 \\\n","--beam 5 \\\n","--lenpen 1 \\\n","--seed 2024 \\\n","--max-len-a 0 \\\n","--max-len-b 100 \\\n","--quiet \\\n","--remove-bpe \\\n","--buffer-size 100 \\\n","--input /content/drive/MyDrive/Research/eng-to-nso/cleaned-data/clean_gtest.eng \\\n","trained_model/ | grep -P \"D-[0-9]+\" | cut -f3 > trained_model/translations_gtest"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3380,"status":"ok","timestamp":1737882723464,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"},"user_tz":-120},"id":"PdeenhNWaFsc","outputId":"b6faeaed-88c9-4a7e-d1d5-8e50e9b18f63"},"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/usr/local/bin/fairseq-interactive\", line 5, in <module>\n","    from fairseq_cli.interactive import cli_main\n","  File \"/content/drive/MyDrive/Research/eng-to-nso/fairseq/fairseq_cli/interactive.py\", line 23, in <module>\n","    from fairseq import checkpoint_utils, distributed_utils, options, tasks, utils\n","  File \"/content/drive/MyDrive/Research/eng-to-nso/fairseq/fairseq/__init__.py\", line 20, in <module>\n","    from fairseq.distributed import utils as distributed_utils\n","  File \"/content/drive/MyDrive/Research/eng-to-nso/fairseq/fairseq/distributed/__init__.py\", line 7, in <module>\n","    from .fully_sharded_data_parallel import (\n","  File \"/content/drive/MyDrive/Research/eng-to-nso/fairseq/fairseq/distributed/fully_sharded_data_parallel.py\", line 10, in <module>\n","    from fairseq.dataclass.configs import DistributedTrainingConfig\n","  File \"/content/drive/MyDrive/Research/eng-to-nso/fairseq/fairseq/dataclass/__init__.py\", line 6, in <module>\n","    from .configs import FairseqDataclass\n","  File \"/content/drive/MyDrive/Research/eng-to-nso/fairseq/fairseq/dataclass/configs.py\", line 1127, in <module>\n","    @dataclass\n","     ^^^^^^^^^\n","  File \"/usr/lib/python3.11/dataclasses.py\", line 1232, in dataclass\n","    return wrap(cls)\n","           ^^^^^^^^^\n","  File \"/usr/lib/python3.11/dataclasses.py\", line 1222, in wrap\n","    return _process_class(cls, init, repr, eq, order, unsafe_hash,\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/dataclasses.py\", line 958, in _process_class\n","    cls_fields.append(_get_field(cls, name, type, kw_only))\n","                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/dataclasses.py\", line 815, in _get_field\n","    raise ValueError(f'mutable default {type(f.default)} for field '\n","ValueError: mutable default <class 'fairseq.dataclass.configs.CommonConfig'> for field common is not allowed: use default_factory\n"]}],"source":["!fairseq-interactive \\\n","--path trained_model/model.pt \\\n","--source-lang eng \\\n","--target-lang nso \\\n","--bpe 'subword_nmt' \\\n","--bpe-codes trained_model/bpe.codes.4000 \\\n","--beam 5 \\\n","--lenpen 1 \\\n","--seed 2024 \\\n","--max-len-a 0 \\\n","--max-len-b 100 \\\n","--quiet \\\n","--remove-bpe \\\n","--buffer-size 100 \\\n","--input /content/drive/MyDrive/Research/eng-to-nso/cleaned-data/test.eng \\\n","trained_model/ | grep -P \"D-[0-9]+\" | cut -f3 > trained_model/translations_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aohCLVVYEJzP"},"outputs":[],"source":["# change working directory\n","os.chdir(f'/content/drive/MyDrive/Research/eng-to-{target_code}/cleaned-data')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2fZqNykwEUSB"},"outputs":[],"source":["translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/bpe/trained_model/translations_gtest'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jlPugTCJEZqn"},"outputs":[],"source":["# post-processing predictions\n","with open(translations_path, 'r', encoding='utf-8') as f:\n","  segments = f.read().splitlines()\n","\n","for i in range(len(segments)):\n","  segments[i] = remove_whitespace_before(segments[i], before_punc)\n","\n","post_translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/bpe/trained_model/post_process_translations_gtest'\n","with open(post_translations_path, 'w') as f:\n","  for segment in segments:\n","    f.write(segment + '\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":986,"status":"ok","timestamp":1730882963788,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"},"user_tz":-120},"id":"VW5-TobpEdud","outputId":"963f6ee3-28f3-43da-dc40-59169064901d"},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n"," \"name\": \"BLEU\",\n"," \"score\": 17.6,\n"," \"signature\": \"nrefs:4|case:mixed|eff:no|tok:none|smooth:add-k[1.00]|version:2.4.3\",\n"," \"verbose_score\": \"51.8/24.4/12.1/6.2 (BP = 1.000 ratio = 1.018 hyp_len = 11776 ref_len = 11569)\",\n"," \"nrefs\": \"4\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"no\",\n"," \"tok\": \"none\",\n"," \"smooth\": \"add-k[1.00]\",\n"," \"version\": \"2.4.3\"\n","}\n","\u001b[0m"]}],"source":["!sacrebleu ref1.nso ref2.nso ref3.nso ref4.nso -i $translations_path -m bleu --force\n","!sacrebleu ref1.nso ref2.nso ref3.nso ref4.nso -i $post_translations_path -m bleu"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"owYAAa6CawQx"},"outputs":[],"source":["translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/bpe/trained_model/translations_test'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f4ZPol1ja1UI"},"outputs":[],"source":["# post-processing predictions\n","with open(translations_path, 'r', encoding='utf-8') as f:\n","  segments = f.read().splitlines()\n","\n","for i in range(len(segments)):\n","  segments[i] = remove_whitespace_before(segments[i], before_punc)\n","\n","post_translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/bpe/trained_model/post_process_translations_test'\n","with open(post_translations_path, 'w') as f:\n","  for segment in segments:\n","    f.write(segment + '\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1723,"status":"ok","timestamp":1730881472476,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"},"user_tz":-120},"id":"SACCxM62bBe_","outputId":"ff8da5a4-7668-446e-ffff-8af3b525ec4b"},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n"," \"name\": \"BLEU\",\n"," \"score\": 18.2,\n"," \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.3\",\n"," \"verbose_score\": \"49.3/23.7/13.8/8.6 (BP = 0.941 ratio = 0.943 hyp_len = 54813 ref_len = 58147)\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.4.3\"\n","}\n","\u001b[0m{\n"," \"name\": \"BLEU\",\n"," \"score\": 18.2,\n"," \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.3\",\n"," \"verbose_score\": \"49.3/23.7/13.8/8.6 (BP = 0.941 ratio = 0.943 hyp_len = 54813 ref_len = 58147)\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.4.3\"\n","}\n","\u001b[0m"]}],"source":["!sacrebleu test.nso -i $translations_path -m bleu --force\n","!sacrebleu test.nso -i $post_translations_path -m bleu"]},{"cell_type":"markdown","metadata":{"id":"iauZD-uv3f_U"},"source":["### ULM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"enHL8Yr7E-YQ"},"outputs":[],"source":["# change working directory\n","os.chdir(f'/content/drive/MyDrive/Research/eng-to-{target_code}/ulm')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ve2z0uigXtBX"},"outputs":[],"source":["!mkdir -p trained_model\n","!cp data-bin/dict.eng.txt trained_model/dict.eng.txt\n","!cp data-bin/dict.nso.txt trained_model/dict.nso.txt\n","!cp data/joint.model trained_model/joint.model\n","!cp checkpoints-ulm/checkpoint_best.pt trained_model/model.pt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":194549,"status":"ok","timestamp":1730881771929,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"},"user_tz":-120},"id":"yXQ1DtgRFFWk","outputId":"76198e6f-d152-467b-f1c1-d59d5052e8dc"},"outputs":[{"name":"stdout","output_type":"stream","text":["2024-11-06 08:26:21.830990: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-06 08:26:21.859909: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-06 08:26:21.869689: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-06 08:26:21.893508: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-06 08:26:23.319758: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-11-06 08:26:32 | INFO | fairseq_cli.interactive | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 2024, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'trained_model/model.pt', 'post_process': 'sentencepiece', 'quiet': True, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 100, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 100, 'input': '/content/drive/MyDrive/Research/eng-to-nso/cleaned-data/clean_gtest.eng'}, 'model': None, 'task': {'_name': 'translation', 'data': 'trained_model/', 'source_lang': 'eng', 'target_lang': 'nso', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': {'_name': 'sentencepiece', 'sentencepiece_model': 'trained_model/joint.model', 'sentencepiece_enable_sampling': False, 'sentencepiece_alpha': None}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2024-11-06 08:26:32 | INFO | fairseq.tasks.translation | [eng] dictionary: 3992 types\n","2024-11-06 08:26:32 | INFO | fairseq.tasks.translation | [nso] dictionary: 3992 types\n","2024-11-06 08:26:32 | INFO | fairseq_cli.interactive | loading model(s) from trained_model/model.pt\n","/content/drive/MyDrive/Research/eng-to-nso/fairseq/fairseq/checkpoint_utils.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state = torch.load(f, map_location=torch.device(\"cpu\"))\n","2024-11-06 08:26:33 | INFO | fairseq_cli.interactive | Sentence buffer size: 100\n","2024-11-06 08:26:33 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n","2024-11-06 08:26:33 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n","2024-11-06 08:26:33 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 08:26:33 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 08:26:33 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 08:26:33 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 08:26:57 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 08:26:57 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 08:26:57 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 08:26:57 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 08:27:38 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 08:27:38 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 08:27:38 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 08:27:38 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 08:28:13 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 08:28:13 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 08:28:13 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 08:28:13 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 08:28:52 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 08:28:52 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 08:28:52 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 08:28:52 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 08:29:29 | INFO | fairseq_cli.interactive | Total time: 176.769 seconds; translation time: 173.751\n"]}],"source":["!fairseq-interactive \\\n","--path trained_model/model.pt \\\n","--source-lang eng \\\n","--target-lang nso \\\n","--bpe 'sentencepiece' \\\n","--sentencepiece-model trained_model/joint.model \\\n","--beam 5 \\\n","--lenpen 1 \\\n","--seed 2024 \\\n","--max-len-a 0 \\\n","--max-len-b 100 \\\n","--quiet \\\n","--remove-bpe sentencepiece \\\n","--buffer-size 100 \\\n","--input /content/drive/MyDrive/Research/eng-to-nso/cleaned-data/clean_gtest.eng \\\n","trained_model/ | grep -P \"H-[0-9]+\" | cut -f3 > trained_model/translations_gtest"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":837194,"status":"ok","timestamp":1730882673847,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"},"user_tz":-120},"id":"eDlcCa-4k8jS","outputId":"152d8c26-8bd3-4fc9-f21f-520ac16a7a5c"},"outputs":[{"name":"stdout","output_type":"stream","text":["2024-11-06 08:30:40.403397: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-06 08:30:40.454459: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-06 08:30:40.480514: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-06 08:30:40.554905: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-06 08:30:42.753024: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-11-06 08:30:52 | INFO | fairseq_cli.interactive | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 2024, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'trained_model/model.pt', 'post_process': 'sentencepiece', 'quiet': True, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 100, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 100, 'input': '/content/drive/MyDrive/Research/eng-to-nso/cleaned-data/test.eng'}, 'model': None, 'task': {'_name': 'translation', 'data': 'trained_model/', 'source_lang': 'eng', 'target_lang': 'nso', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': {'_name': 'sentencepiece', 'sentencepiece_model': 'trained_model/joint.model', 'sentencepiece_enable_sampling': False, 'sentencepiece_alpha': None}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2024-11-06 08:30:52 | INFO | fairseq.tasks.translation | [eng] dictionary: 3992 types\n","2024-11-06 08:30:52 | INFO | fairseq.tasks.translation | [nso] dictionary: 3992 types\n","2024-11-06 08:30:52 | INFO | fairseq_cli.interactive | loading model(s) from trained_model/model.pt\n","/content/drive/MyDrive/Research/eng-to-nso/fairseq/fairseq/checkpoint_utils.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state = torch.load(f, map_location=torch.device(\"cpu\"))\n","2024-11-06 08:30:52 | INFO | fairseq_cli.interactive | Sentence buffer size: 100\n","2024-11-06 08:30:52 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n","2024-11-06 08:30:52 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n","2024-11-06 08:30:52 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 08:30:52 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 08:30:52 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 08:30:52 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 08:31:20 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 08:31:20 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 08:31:20 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 08:31:20 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 08:31:47 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 08:31:47 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 08:31:47 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 08:31:47 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 08:32:17 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 08:32:17 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 08:32:17 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 08:32:17 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 08:32:44 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 08:32:44 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 08:32:44 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 08:32:44 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 08:33:12 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 08:33:12 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 08:33:12 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 08:33:12 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 08:33:39 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 08:33:39 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 08:33:39 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 08:33:39 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 08:34:07 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 08:34:07 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 08:34:07 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 08:34:07 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 08:34:35 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 08:34:35 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 08:34:35 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 08:34:35 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 08:35:06 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 08:35:06 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 08:35:06 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 08:35:06 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 08:35:31 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 08:35:31 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 08:35:31 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 08:35:31 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 08:35:57 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 08:35:57 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 08:35:57 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 08:35:57 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 08:36:24 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 08:36:24 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 08:36:24 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 08:36:24 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 08:36:49 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 08:36:49 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 08:36:49 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 08:36:49 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 08:37:20 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 08:37:20 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 08:37:20 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 08:37:20 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 08:37:48 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 08:37:48 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 08:37:48 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 08:37:48 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 08:38:13 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 08:38:13 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 08:38:13 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 08:38:13 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 08:38:39 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 08:38:39 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 08:38:39 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 08:38:39 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 08:39:05 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 08:39:05 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 08:39:05 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 08:39:05 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 08:39:31 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 08:39:32 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 08:39:32 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 08:39:32 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 08:39:58 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 08:39:58 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 08:39:58 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 08:39:58 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 08:40:23 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 08:40:23 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 08:40:23 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 08:40:23 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 08:40:53 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 08:40:53 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 08:40:53 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 08:40:53 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 08:41:20 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 08:41:20 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 08:41:20 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 08:41:20 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 08:41:49 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 08:41:49 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 08:41:49 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 08:41:49 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 08:42:19 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 08:42:19 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 08:42:19 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 08:42:19 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 08:42:46 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 08:42:46 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 08:42:46 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 08:42:46 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 08:43:11 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 08:43:11 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 08:43:11 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 08:43:11 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 08:43:37 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 08:43:37 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 08:43:37 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 08:43:37 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 08:44:04 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 08:44:04 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 08:44:04 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 08:44:04 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 08:44:30 | INFO | fairseq_cli.interactive | Total time: 818.717 seconds; translation time: 807.731\n"]}],"source":["!fairseq-interactive \\\n","--path trained_model/model.pt \\\n","--source-lang eng \\\n","--target-lang nso \\\n","--bpe 'sentencepiece' \\\n","--sentencepiece-model trained_model/joint.model \\\n","--beam 5 \\\n","--lenpen 1 \\\n","--seed 2024 \\\n","--max-len-a 0 \\\n","--max-len-b 100 \\\n","--quiet \\\n","--remove-bpe sentencepiece \\\n","--buffer-size 100 \\\n","--input /content/drive/MyDrive/Research/eng-to-nso/cleaned-data/test.eng \\\n","trained_model/ | grep -P \"H-[0-9]+\" | cut -f3 > trained_model/translations_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OoR_vcnXLFwc"},"outputs":[],"source":["# change working directory\n","os.chdir(f'/content/drive/MyDrive/Research/eng-to-{target_code}/cleaned-data')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"muW-UzGh__kN"},"outputs":[],"source":["translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/ulm/trained_model/translations_gtest'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4i8zSs8SJOZ-"},"outputs":[],"source":["# post-processing predictions\n","with open(translations_path, 'r', encoding='utf-8') as f:\n","  segments = f.read().splitlines()\n","\n","for i in range(len(segments)):\n","  segments[i] = remove_whitespace_before(segments[i], before_punc)\n","\n","post_translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/ulm/trained_model/post_process_translations_gtest'\n","with open(post_translations_path, 'w') as f:\n","  for segment in segments:\n","    f.write(segment + '\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DuDGTWM0lquS"},"outputs":[],"source":["translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/ulm/trained_model/translations_test'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rc0uZKX_lwH_"},"outputs":[],"source":["# post-processing predictions\n","with open(translations_path, 'r', encoding='utf-8') as f:\n","  segments = f.read().splitlines()\n","\n","for i in range(len(segments)):\n","  segments[i] = remove_whitespace_before(segments[i], before_punc)\n","\n","post_translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/ulm/trained_model/post_process_translations_test'\n","with open(post_translations_path, 'w') as f:\n","  for segment in segments:\n","    f.write(segment + '\\n')"]},{"cell_type":"markdown","metadata":{"id":"a_Iql_RCATZN"},"source":["### BPE-Dropout"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Tb95T9dAaaE"},"outputs":[],"source":["# change working directory\n","os.chdir(f'/content/drive/MyDrive/Research/eng-to-{target_code}/bpeDROP')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bvYGLuCYAcKB"},"outputs":[],"source":["!mkdir -p trained_model\n","!cp data-bin-25/dict.eng.txt trained_model/dict.eng.txt\n","!cp data-bin-25/dict.nso.txt trained_model/dict.nso.txt\n","!cp /content/drive/MyDrive/Research/eng-to-nso/bpe/data/bpe.codes.4000 trained_model/bpe.codes.4000\n","!cp checkpoints-bpeDROP/checkpoint_best.pt trained_model/model.pt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":207869,"status":"ok","timestamp":1730884785269,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"},"user_tz":-120},"id":"W5rWtiClAhsS","outputId":"904327d2-a12e-4080-9cea-17259e8dd9ec"},"outputs":[{"name":"stdout","output_type":"stream","text":["2024-11-06 09:16:20.385786: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-06 09:16:20.466807: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-06 09:16:20.492546: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-06 09:16:20.548231: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-06 09:16:22.564301: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-11-06 09:16:39 | INFO | fairseq_cli.interactive | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 2024, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'trained_model/model.pt', 'post_process': 'subword_nmt', 'quiet': True, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 100, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 100, 'input': '/content/drive/MyDrive/Research/eng-to-nso/cleaned-data/clean_gtest.eng'}, 'model': None, 'task': {'_name': 'translation', 'data': 'trained_model/', 'source_lang': 'eng', 'target_lang': 'nso', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': {'_name': 'subword_nmt', 'bpe_codes': 'trained_model/bpe.codes.4000', 'bpe_separator': '@@'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2024-11-06 09:16:39 | INFO | fairseq.tasks.translation | [eng] dictionary: 4160 types\n","2024-11-06 09:16:39 | INFO | fairseq.tasks.translation | [nso] dictionary: 4160 types\n","2024-11-06 09:16:39 | INFO | fairseq_cli.interactive | loading model(s) from trained_model/model.pt\n","/content/drive/MyDrive/Research/eng-to-nso/fairseq/fairseq/checkpoint_utils.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state = torch.load(f, map_location=torch.device(\"cpu\"))\n","2024-11-06 09:16:40 | INFO | fairseq_cli.interactive | Sentence buffer size: 100\n","2024-11-06 09:16:40 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n","2024-11-06 09:16:40 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n","2024-11-06 09:16:40 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:16:40 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:16:40 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:16:40 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:17:07 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:17:07 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:17:07 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:17:07 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:17:47 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:17:47 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:17:47 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:17:47 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:18:25 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:18:25 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:18:25 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:18:25 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:19:04 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:19:04 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:19:04 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:19:04 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:19:42 | INFO | fairseq_cli.interactive | Total time: 183.977 seconds; translation time: 180.749\n"]}],"source":["!fairseq-interactive \\\n","--path trained_model/model.pt \\\n","--source-lang eng \\\n","--target-lang nso \\\n","--bpe 'subword_nmt' \\\n","--bpe-codes trained_model/bpe.codes.4000 \\\n","--beam 5 \\\n","--lenpen 1 \\\n","--seed 2024 \\\n","--max-len-a 0 \\\n","--max-len-b 100 \\\n","--quiet \\\n","--remove-bpe \\\n","--buffer-size 100 \\\n","--input /content/drive/MyDrive/Research/eng-to-nso/cleaned-data/clean_gtest.eng \\\n","trained_model/ | grep -P \"D-[0-9]+\" | cut -f3 > trained_model/translations_gtest"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":803815,"status":"ok","timestamp":1730885589080,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"},"user_tz":-120},"id":"9vALUB8ZrUVA","outputId":"5d9466c1-2c70-4d6a-e5f5-9743ed3f191b"},"outputs":[{"name":"stdout","output_type":"stream","text":["2024-11-06 09:19:47.592644: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-06 09:19:47.616877: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-06 09:19:47.624039: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-06 09:19:47.641578: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-06 09:19:49.132663: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-11-06 09:19:59 | INFO | fairseq_cli.interactive | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 2024, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'trained_model/model.pt', 'post_process': 'subword_nmt', 'quiet': True, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 100, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 100, 'input': '/content/drive/MyDrive/Research/eng-to-nso/cleaned-data/test.eng'}, 'model': None, 'task': {'_name': 'translation', 'data': 'trained_model/', 'source_lang': 'eng', 'target_lang': 'nso', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': {'_name': 'subword_nmt', 'bpe_codes': 'trained_model/bpe.codes.4000', 'bpe_separator': '@@'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2024-11-06 09:19:59 | INFO | fairseq.tasks.translation | [eng] dictionary: 4160 types\n","2024-11-06 09:19:59 | INFO | fairseq.tasks.translation | [nso] dictionary: 4160 types\n","2024-11-06 09:19:59 | INFO | fairseq_cli.interactive | loading model(s) from trained_model/model.pt\n","/content/drive/MyDrive/Research/eng-to-nso/fairseq/fairseq/checkpoint_utils.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state = torch.load(f, map_location=torch.device(\"cpu\"))\n","2024-11-06 09:20:00 | INFO | fairseq_cli.interactive | Sentence buffer size: 100\n","2024-11-06 09:20:00 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n","2024-11-06 09:20:00 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n","2024-11-06 09:20:00 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:20:00 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:20:00 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:20:00 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:20:27 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:20:27 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:20:27 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:20:27 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:20:51 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:20:51 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:20:51 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:20:51 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:21:17 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:21:17 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:21:17 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:21:17 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:21:44 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:21:44 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:21:44 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:21:44 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:22:09 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:22:09 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:22:09 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:22:09 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:22:36 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:22:36 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:22:36 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:22:36 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:23:03 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:23:03 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:23:03 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:23:03 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:23:28 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:23:28 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:23:28 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:23:28 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:23:56 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:23:56 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:23:56 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:23:56 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:24:21 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:24:21 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:24:21 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:24:21 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:24:45 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:24:45 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:24:45 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:24:45 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:25:11 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:25:11 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:25:11 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:25:11 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:25:36 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:25:36 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:25:36 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:25:36 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:26:03 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:26:03 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:26:03 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:26:03 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:26:30 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:26:30 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:26:30 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:26:30 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:26:56 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:26:56 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:26:56 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:26:56 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:27:20 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:27:20 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:27:20 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:27:20 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:27:47 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:27:47 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:27:47 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:27:47 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:28:12 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:28:12 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:28:12 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:28:12 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:28:37 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:28:37 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:28:37 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:28:37 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:29:02 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:29:02 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:29:02 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:29:02 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:29:30 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:29:30 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:29:30 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:29:30 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:29:56 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:29:56 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:29:56 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:29:56 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:30:25 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:30:25 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:30:25 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:30:25 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:30:57 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:30:57 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:30:57 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:30:57 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:31:24 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:31:24 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:31:24 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:31:24 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:31:48 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:31:48 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:31:48 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:31:48 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:32:14 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:32:14 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:32:14 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:32:14 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:32:39 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:32:39 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:32:39 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:32:39 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:33:06 | INFO | fairseq_cli.interactive | Total time: 786.463 seconds; translation time: 775.557\n"]}],"source":["!fairseq-interactive \\\n","--path trained_model/model.pt \\\n","--source-lang eng \\\n","--target-lang nso \\\n","--bpe 'subword_nmt' \\\n","--bpe-codes trained_model/bpe.codes.4000 \\\n","--beam 5 \\\n","--lenpen 1 \\\n","--seed 2024 \\\n","--max-len-a 0 \\\n","--max-len-b 100 \\\n","--quiet \\\n","--remove-bpe \\\n","--buffer-size 100 \\\n","--input /content/drive/MyDrive/Research/eng-to-nso/cleaned-data/test.eng \\\n","trained_model/ | grep -P \"D-[0-9]+\" | cut -f3 > trained_model/translations_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d76ynahbAnfh"},"outputs":[],"source":["# change working directory\n","os.chdir(f'/content/drive/MyDrive/Research/eng-to-{target_code}/cleaned-data')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G9zywHBYArTh"},"outputs":[],"source":["translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/bpeDROP/trained_model/translations_gtest'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"08570vDoAsLe"},"outputs":[],"source":["# post-processing predictions\n","with open(translations_path, 'r', encoding='utf-8') as f:\n","  segments = f.read().splitlines()\n","\n","for i in range(len(segments)):\n","  segments[i] = remove_whitespace_before(segments[i], before_punc)\n","\n","post_translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/bpeDROP/trained_model/post_process_translations_gtest'\n","with open(post_translations_path, 'w') as f:\n","  for segment in segments:\n","    f.write(segment + '\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6W5o9_1isd8I"},"outputs":[],"source":["translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/bpeDROP/trained_model/translations_test'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JGfF9Mycsg6L"},"outputs":[],"source":["# post-processing predictions\n","with open(translations_path, 'r', encoding='utf-8') as f:\n","  segments = f.read().splitlines()\n","\n","for i in range(len(segments)):\n","  segments[i] = remove_whitespace_before(segments[i], before_punc)\n","\n","post_translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/bpeDROP/trained_model/post_process_translations_test'\n","with open(post_translations_path, 'w') as f:\n","  for segment in segments:\n","    f.write(segment + '\\n')"]},{"cell_type":"markdown","metadata":{"id":"N3ONkIS9AVJ6"},"source":["### ULM with Subword Regularization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o75Z3YSWAzP1"},"outputs":[],"source":["# change working directory\n","os.chdir(f'/content/drive/MyDrive/Research/eng-to-{target_code}/ulmSR')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CUBebHahBGx5"},"outputs":[],"source":["!mkdir -p trained_model\n","!cp data-bin-25/dict.eng.txt trained_model/dict.eng.txt\n","!cp data-bin-25/dict.nso.txt trained_model/dict.nso.txt\n","!cp /content/drive/MyDrive/Research/eng-to-nso/ulm/data/joint.model trained_model/joint.model\n","!cp checkpoints-ulmSR/checkpoint_best.pt trained_model/model.pt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":279166,"status":"ok","timestamp":1730885874555,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"},"user_tz":-120},"id":"2_g7Jrq1BJ_0","outputId":"26945eb5-9c7b-4dc6-f82a-a281142d59a9"},"outputs":[{"name":"stdout","output_type":"stream","text":["2024-11-06 09:33:18.466989: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-06 09:33:18.492209: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-06 09:33:18.499204: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-06 09:33:18.517116: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-06 09:33:19.989952: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-11-06 09:33:31 | INFO | fairseq_cli.interactive | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 2024, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'trained_model/model.pt', 'post_process': 'sentencepiece', 'quiet': True, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 100, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 100, 'input': '/content/drive/MyDrive/Research/eng-to-nso/cleaned-data/clean_gtest.eng'}, 'model': None, 'task': {'_name': 'translation', 'data': 'trained_model/', 'source_lang': 'eng', 'target_lang': 'nso', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': {'_name': 'sentencepiece', 'sentencepiece_model': 'trained_model/joint.model', 'sentencepiece_enable_sampling': False, 'sentencepiece_alpha': None}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2024-11-06 09:33:31 | INFO | fairseq.tasks.translation | [eng] dictionary: 3992 types\n","2024-11-06 09:33:31 | INFO | fairseq.tasks.translation | [nso] dictionary: 3992 types\n","2024-11-06 09:33:31 | INFO | fairseq_cli.interactive | loading model(s) from trained_model/model.pt\n","/content/drive/MyDrive/Research/eng-to-nso/fairseq/fairseq/checkpoint_utils.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state = torch.load(f, map_location=torch.device(\"cpu\"))\n","2024-11-06 09:33:31 | INFO | fairseq_cli.interactive | Sentence buffer size: 100\n","2024-11-06 09:33:31 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n","2024-11-06 09:33:31 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n","2024-11-06 09:33:32 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:33:32 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:33:32 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:33:32 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:34:09 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:34:09 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:34:09 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:34:09 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:35:09 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:35:09 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:35:09 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:35:09 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:36:05 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:36:05 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:36:05 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:36:05 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:37:00 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:37:00 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:37:00 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:37:00 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:37:52 | INFO | fairseq_cli.interactive | Total time: 260.730 seconds; translation time: 257.791\n"]}],"source":["!fairseq-interactive \\\n","--path trained_model/model.pt \\\n","--source-lang eng \\\n","--target-lang nso \\\n","--bpe 'sentencepiece' \\\n","--sentencepiece-model trained_model/joint.model \\\n","--beam 5 \\\n","--lenpen 1 \\\n","--seed 2024 \\\n","--max-len-a 0 \\\n","--max-len-b 100 \\\n","--quiet \\\n","--remove-bpe sentencepiece \\\n","--buffer-size 100 \\\n","--input /content/drive/MyDrive/Research/eng-to-nso/cleaned-data/clean_gtest.eng \\\n","trained_model/ | grep -P \"H-[0-9]+\" | cut -f3 > trained_model/translations_gtest"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1344567,"status":"ok","timestamp":1730887219110,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"},"user_tz":-120},"id":"rbPrS2aEvhfV","outputId":"62cc9860-77c6-497a-9264-1bc6d9aa42c0"},"outputs":[{"name":"stdout","output_type":"stream","text":["2024-11-06 09:37:58.122371: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-06 09:37:58.162003: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-06 09:37:58.173934: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-06 09:37:58.201253: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-06 09:38:00.133073: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-11-06 09:38:09 | INFO | fairseq_cli.interactive | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 2024, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'trained_model/model.pt', 'post_process': 'sentencepiece', 'quiet': True, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 100, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 100, 'input': '/content/drive/MyDrive/Research/eng-to-nso/cleaned-data/test.eng'}, 'model': None, 'task': {'_name': 'translation', 'data': 'trained_model/', 'source_lang': 'eng', 'target_lang': 'nso', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': {'_name': 'sentencepiece', 'sentencepiece_model': 'trained_model/joint.model', 'sentencepiece_enable_sampling': False, 'sentencepiece_alpha': None}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2024-11-06 09:38:09 | INFO | fairseq.tasks.translation | [eng] dictionary: 3992 types\n","2024-11-06 09:38:09 | INFO | fairseq.tasks.translation | [nso] dictionary: 3992 types\n","2024-11-06 09:38:09 | INFO | fairseq_cli.interactive | loading model(s) from trained_model/model.pt\n","/content/drive/MyDrive/Research/eng-to-nso/fairseq/fairseq/checkpoint_utils.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state = torch.load(f, map_location=torch.device(\"cpu\"))\n","2024-11-06 09:38:10 | INFO | fairseq_cli.interactive | Sentence buffer size: 100\n","2024-11-06 09:38:10 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n","2024-11-06 09:38:10 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n","2024-11-06 09:38:10 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:38:10 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:38:10 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:38:10 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:38:53 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:38:53 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:38:53 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:38:53 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:39:37 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:39:37 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:39:37 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:39:37 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:40:19 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:40:19 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:40:19 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:40:19 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:41:05 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:41:05 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:41:05 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:41:05 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:41:51 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:41:51 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:41:51 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:41:51 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:42:36 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:42:36 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:42:36 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:42:36 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:43:21 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:43:21 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:43:21 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:43:21 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:44:07 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:44:07 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:44:07 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:44:07 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:44:53 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:44:53 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:44:53 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:44:53 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:45:38 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:45:38 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:45:38 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:45:38 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:46:20 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:46:20 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:46:20 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:46:20 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:47:05 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:47:05 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:47:05 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:47:05 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:47:46 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:47:46 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:47:46 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:47:46 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:48:36 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:48:36 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:48:36 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:48:36 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:49:22 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:49:22 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:49:22 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:49:22 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:50:06 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:50:06 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:50:06 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:50:06 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:50:50 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:50:50 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:50:50 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:50:50 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:51:32 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:51:32 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:51:32 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:51:32 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:52:13 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:52:13 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:52:13 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:52:13 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:52:53 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:52:53 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:52:53 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:52:53 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:53:37 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:53:37 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:53:37 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:53:37 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:54:25 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:54:25 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:54:25 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:54:25 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:55:10 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:55:10 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:55:10 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:55:10 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:55:57 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:55:57 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:55:57 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:55:57 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:56:43 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:56:43 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:56:43 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:56:43 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:57:29 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:57:29 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:57:29 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:57:29 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:58:09 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:58:09 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:58:09 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:58:09 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:58:55 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:58:55 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:58:55 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:58:55 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 09:59:35 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 09:59:35 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 09:59:35 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 09:59:35 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:00:16 | INFO | fairseq_cli.interactive | Total time: 1327.139 seconds; translation time: 1315.299\n"]}],"source":["!fairseq-interactive \\\n","--path trained_model/model.pt \\\n","--source-lang eng \\\n","--target-lang nso \\\n","--bpe 'sentencepiece' \\\n","--sentencepiece-model trained_model/joint.model \\\n","--beam 5 \\\n","--lenpen 1 \\\n","--seed 2024 \\\n","--max-len-a 0 \\\n","--max-len-b 100 \\\n","--quiet \\\n","--remove-bpe sentencepiece \\\n","--buffer-size 100 \\\n","--input /content/drive/MyDrive/Research/eng-to-nso/cleaned-data/test.eng \\\n","trained_model/ | grep -P \"H-[0-9]+\" | cut -f3 > trained_model/translations_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3JrJMzVFBOkM"},"outputs":[],"source":["# change working directory\n","os.chdir(f'/content/drive/MyDrive/Research/eng-to-{target_code}/cleaned-data')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Od8oBoyEBTC-"},"outputs":[],"source":["translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/ulmSR/trained_model/translations_gtest'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DkCzOq63BUzI"},"outputs":[],"source":["# post-processing predictions\n","with open(translations_path, 'r', encoding='utf-8') as f:\n","  segments = f.read().splitlines()\n","\n","for i in range(len(segments)):\n","  segments[i] = remove_whitespace_before(segments[i], before_punc)\n","\n","post_translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/ulmSR/trained_model/post_process_translations_gtest'\n","with open(post_translations_path, 'w') as f:\n","  for segment in segments:\n","    f.write(segment + '\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3wcGkJ3UvvnX"},"outputs":[],"source":["translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/ulmSR/trained_model/translations_test'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0zh_Cv3jv6Nv"},"outputs":[],"source":["# post-processing predictions\n","with open(translations_path, 'r', encoding='utf-8') as f:\n","  segments = f.read().splitlines()\n","\n","for i in range(len(segments)):\n","  segments[i] = remove_whitespace_before(segments[i], before_punc)\n","\n","post_translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/ulmSR/trained_model/post_process_translations_test'\n","with open(post_translations_path, 'w') as f:\n","  for segment in segments:\n","    f.write(segment + '\\n')"]},{"cell_type":"markdown","metadata":{"id":"dzefCHIXPNMx"},"source":["### Task-specific Tokenization\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y2ksiWA2PVTx"},"outputs":[],"source":["# change working directory\n","os.chdir(f'/content/drive/MyDrive/Research/eng-to-{target_code}/target-tok')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IrdiUOzHPZ93"},"outputs":[],"source":["!mkdir -p trained_model\n","!cp data-bin-nmt/dict.eng.txt trained_model/dict.eng.txt\n","!cp data-bin-nmt/dict.nso.txt trained_model/dict.nso.txt\n","!cp /content/drive/MyDrive/Research/eng-to-nso/ulm/data/joint.model trained_model/joint.model\n","!cp checkpoints-task-nmt/checkpoint_best.pt trained_model/model.pt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":200269,"status":"ok","timestamp":1730887423622,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"},"user_tz":-120},"id":"ANHE6pHNPv-B","outputId":"6b6e1b2e-9471-4b98-a9b5-45315418ad9e"},"outputs":[{"name":"stdout","output_type":"stream","text":["2024-11-06 10:00:26.579153: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-06 10:00:26.602519: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-06 10:00:26.609322: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-06 10:00:26.626659: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-06 10:00:28.010778: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-11-06 10:00:40 | INFO | fairseq_cli.interactive | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 2024, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'trained_model/model.pt', 'post_process': 'sentencepiece', 'quiet': True, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 100, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 100, 'input': '/content/drive/MyDrive/Research/eng-to-nso/cleaned-data/clean_gtest.eng'}, 'model': None, 'task': {'_name': 'translation', 'data': 'trained_model/', 'source_lang': 'eng', 'target_lang': 'nso', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': {'_name': 'sentencepiece', 'sentencepiece_model': 'trained_model/joint.model', 'sentencepiece_enable_sampling': False, 'sentencepiece_alpha': None}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2024-11-06 10:00:40 | INFO | fairseq.tasks.translation | [eng] dictionary: 3992 types\n","2024-11-06 10:00:40 | INFO | fairseq.tasks.translation | [nso] dictionary: 3992 types\n","2024-11-06 10:00:40 | INFO | fairseq_cli.interactive | loading model(s) from trained_model/model.pt\n","/content/drive/MyDrive/Research/eng-to-nso/fairseq/fairseq/checkpoint_utils.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state = torch.load(f, map_location=torch.device(\"cpu\"))\n","2024-11-06 10:00:42 | INFO | fairseq_cli.interactive | Sentence buffer size: 100\n","2024-11-06 10:00:42 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n","2024-11-06 10:00:42 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n","2024-11-06 10:00:42 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:00:42 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:00:42 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:00:42 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:01:07 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:01:07 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:01:07 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:01:07 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:01:46 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:01:46 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:01:46 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:01:46 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:02:23 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:02:23 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:02:23 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:02:23 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:03:03 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:03:03 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:03:03 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:03:03 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:03:40 | INFO | fairseq_cli.interactive | Total time: 180.469 seconds; translation time: 176.234\n"]}],"source":["!fairseq-interactive \\\n","--path trained_model/model.pt \\\n","--source-lang eng \\\n","--target-lang nso \\\n","--bpe 'sentencepiece' \\\n","--sentencepiece-model trained_model/joint.model \\\n","--beam 5 \\\n","--lenpen 1 \\\n","--seed 2024 \\\n","--max-len-a 0 \\\n","--max-len-b 100 \\\n","--quiet \\\n","--remove-bpe sentencepiece \\\n","--buffer-size 100 \\\n","--input /content/drive/MyDrive/Research/eng-to-nso/cleaned-data/clean_gtest.eng \\\n","trained_model/ | grep -P \"H-[0-9]+\" | cut -f3 > trained_model/translations_gtest"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":852442,"status":"ok","timestamp":1730888276040,"user":{"displayName":"Manala Tyobeka","userId":"00026225086725183959"},"user_tz":-120},"id":"uuL6aGa7xHXX","outputId":"0f0b8294-44f0-455f-fd1e-ec351524786d"},"outputs":[{"name":"stdout","output_type":"stream","text":["2024-11-06 10:03:46.677705: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-06 10:03:46.721511: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-06 10:03:46.731476: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-06 10:03:46.755291: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-06 10:03:48.259407: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-11-06 10:03:58 | INFO | fairseq_cli.interactive | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 2024, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'trained_model/model.pt', 'post_process': 'sentencepiece', 'quiet': True, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 100, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 100, 'input': '/content/drive/MyDrive/Research/eng-to-nso/cleaned-data/test.eng'}, 'model': None, 'task': {'_name': 'translation', 'data': 'trained_model/', 'source_lang': 'eng', 'target_lang': 'nso', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': {'_name': 'sentencepiece', 'sentencepiece_model': 'trained_model/joint.model', 'sentencepiece_enable_sampling': False, 'sentencepiece_alpha': None}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2024-11-06 10:03:58 | INFO | fairseq.tasks.translation | [eng] dictionary: 3992 types\n","2024-11-06 10:03:58 | INFO | fairseq.tasks.translation | [nso] dictionary: 3992 types\n","2024-11-06 10:03:58 | INFO | fairseq_cli.interactive | loading model(s) from trained_model/model.pt\n","/content/drive/MyDrive/Research/eng-to-nso/fairseq/fairseq/checkpoint_utils.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state = torch.load(f, map_location=torch.device(\"cpu\"))\n","2024-11-06 10:03:59 | INFO | fairseq_cli.interactive | Sentence buffer size: 100\n","2024-11-06 10:03:59 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n","2024-11-06 10:03:59 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n","2024-11-06 10:03:59 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:03:59 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:03:59 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:03:59 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:04:25 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:04:25 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:04:25 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:04:25 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:04:52 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:04:52 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:04:52 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:04:52 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:05:20 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:05:20 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:05:20 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:05:20 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:05:49 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:05:49 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:05:49 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:05:49 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:06:18 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:06:18 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:06:18 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:06:18 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:06:46 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:06:46 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:06:46 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:06:46 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:07:12 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:07:12 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:07:12 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:07:12 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:07:42 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:07:42 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:07:42 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:07:42 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:08:12 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:08:12 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:08:12 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:08:12 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:08:42 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:08:42 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:08:42 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:08:42 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:09:08 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:09:08 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:09:08 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:09:08 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:09:36 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:09:36 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:09:36 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:09:36 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:10:02 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:10:02 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:10:02 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:10:02 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:10:32 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:10:32 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:10:32 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:10:32 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:11:00 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:11:00 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:11:00 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:11:00 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:11:26 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:11:26 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:11:26 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:11:26 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:11:52 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:11:52 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:11:52 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:11:52 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:12:19 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:12:19 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:12:19 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:12:19 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:12:45 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:12:45 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:12:45 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:12:45 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:13:13 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:13:13 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:13:13 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:13:13 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:13:41 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:13:41 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:13:41 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:13:41 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:14:11 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:14:11 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:14:11 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:14:11 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:14:38 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:14:38 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:14:38 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:14:38 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:15:07 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:15:07 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:15:07 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:15:07 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:15:38 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:15:38 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:15:38 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:15:38 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:16:07 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:16:07 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:16:07 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:16:07 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:16:34 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:16:34 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:16:34 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:16:34 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:17:00 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:17:00 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:17:00 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:17:00 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:17:26 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n","2024-11-06 10:17:26 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n","2024-11-06 10:17:26 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n","2024-11-06 10:17:26 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n","2024-11-06 10:17:53 | INFO | fairseq_cli.interactive | Total time: 835.437 seconds; translation time: 824.172\n"]}],"source":["!fairseq-interactive \\\n","--path trained_model/model.pt \\\n","--source-lang eng \\\n","--target-lang nso \\\n","--bpe 'sentencepiece' \\\n","--sentencepiece-model trained_model/joint.model \\\n","--beam 5 \\\n","--lenpen 1 \\\n","--seed 2024 \\\n","--max-len-a 0 \\\n","--max-len-b 100 \\\n","--quiet \\\n","--remove-bpe sentencepiece \\\n","--buffer-size 100 \\\n","--input /content/drive/MyDrive/Research/eng-to-nso/cleaned-data/test.eng \\\n","trained_model/ | grep -P \"H-[0-9]+\" | cut -f3 > trained_model/translations_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qvSam-qxPycJ"},"outputs":[],"source":["# change working directory\n","os.chdir(f'/content/drive/MyDrive/Research/eng-to-{target_code}/cleaned-data')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hc1X_HU8P3x4"},"outputs":[],"source":["translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/target-tok/trained_model/translations_gtest'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1YDgxEXTP5dP"},"outputs":[],"source":["# post-processing predictions\n","with open(translations_path, 'r', encoding='utf-8') as f:\n","  segments = f.read().splitlines()\n","\n","for i in range(len(segments)):\n","  segments[i] = remove_whitespace_before(segments[i], before_punc)\n","\n","post_translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/target-tok/trained_model/post_process_translations_gtest'\n","with open(post_translations_path, 'w') as f:\n","  for segment in segments:\n","    f.write(segment + '\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"spVbfgbZxQGH"},"outputs":[],"source":["translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/target-tok/trained_model/translations_test'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lz5aGK2CxUfq"},"outputs":[],"source":["# post-processing predictions\n","with open(translations_path, 'r', encoding='utf-8') as f:\n","  segments = f.read().splitlines()\n","\n","for i in range(len(segments)):\n","  segments[i] = remove_whitespace_before(segments[i], before_punc)\n","\n","post_translations_path = f'/content/drive/MyDrive/Research/eng-to-{target_code}/target-tok/trained_model/post_process_translations_test'\n","with open(post_translations_path, 'w') as f:\n","  for segment in segments:\n","    f.write(segment + '\\n')"]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1B2_v30VIzbsSDex-bi-jlIK92SZZEhs8","authorship_tag":"ABX9TyNTRltQRMK5w2bt4ydvtKSd"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}